{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# total loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tower_loss(scope):\n",
    "    images, labels = cifar10.distorted_inputs()\n",
    "    # call cnn from inference\n",
    "    logits = cifar10.inference(images)\n",
    "    _ = cifar10.loss(logits, labels)\n",
    "    losses = tf.get_collection('losses', scope)\n",
    "    total_loss = tf.add_n(losses, name='total_loss')\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# avg gradients function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_gradients(tower_grads):\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "        grads = []\n",
    "        for g, _ in grad_and_vars:\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "            grads.append(expanded_g)\n",
    "            \n",
    "        grad = tf.concat(grads, 0)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "        \n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    with tf.Graph().as_default(), tf.device('/cpu:0'):\n",
    "        global_step = tf.get_variable('global_step', [],\n",
    "                                     initializer=tf.constant_initializer(0), trainable=False)\n",
    "        \n",
    "        num_batches_per_epoch = cifar10.NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / batch_size\n",
    "        decay_steps = int(num_batches_per_epoch * cifar10.NUM_EPOCHS_PER_DECAY)\n",
    "        \n",
    "        lr = tf.train.exponential_decay(cifar10.INITIAL_LEARNING_RATE,\n",
    "                                       global_step, decay_steps, cifar10.LEARNING_RATE_DECAY_FACTOR, staircase=True)\n",
    "        \n",
    "        opt = tf.train.GradientDescentOptimizer(lr)\n",
    "        \n",
    "        # gpu gradient distributed\n",
    "        tower_grads = []\n",
    "        for i in range(num_gpus):\n",
    "            with tf.device('/gpu:%d' % i):\n",
    "                with tf.name_scope('%s_%d' % (cifar10.TOWER_NAME, i)) as scope:\n",
    "                    loss = tower_loss(scope)\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "                    # single gpu gradient\n",
    "                    grads = opt.compute_gradients(loss)\n",
    "                    tower_grads.append(grads)\n",
    "                    \n",
    "        # update model gradients\n",
    "        grads = average_gradients(tower_grads)\n",
    "        apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "        \n",
    "        # session and allow_soft_placement\n",
    "        saver = tf.train.Saver(tf.all_variables())\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "        sess.run(init)\n",
    "        tf.train.start_queue_runners(sess=sess)\n",
    "        \n",
    "        # batch loss and time\n",
    "        for step in range(max_steps):\n",
    "            start_time = time.time()\n",
    "            _, loss_value = sess.run([apply_gradient_op, loss])\n",
    "            duration = time.time() - start_time\n",
    "            \n",
    "            if step % 10 == 0:\n",
    "                num_examples_per_step = batch_size * num_gpus\n",
    "                examples_per_sec = num_examples_per_step / duration\n",
    "                sec_per_batch = duration / num_gpus\n",
    "                \n",
    "                format_str = ('step %d, loss = %.2f (%.1f examples/sec; %.3f sec/batch)')\n",
    "                print(format_str % (step, loss_value, examples_per_sec, sec_per_batch))\n",
    "                \n",
    "            if step % 1000 == 0 or (step + 1) == max_steps:\n",
    "                saver.save(sess, 'cifar10/train_model.ckpt', global_step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "WARNING:tensorflow:From <ipython-input-4-d99f3cf4f1bc>:30: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "step 0, loss = 4.68 (13.6 examples/sec; 9.426 sec/batch)\n",
      "step 10, loss = 4.61 (1706.9 examples/sec; 0.075 sec/batch)\n",
      "step 20, loss = 4.55 (1820.6 examples/sec; 0.070 sec/batch)\n",
      "step 30, loss = 4.41 (1801.0 examples/sec; 0.071 sec/batch)\n",
      "step 40, loss = 4.30 (1924.6 examples/sec; 0.067 sec/batch)\n",
      "step 50, loss = 4.26 (1814.4 examples/sec; 0.071 sec/batch)\n",
      "step 60, loss = 4.28 (1877.9 examples/sec; 0.068 sec/batch)\n",
      "step 70, loss = 4.13 (1742.5 examples/sec; 0.073 sec/batch)\n",
      "step 80, loss = 4.19 (1812.0 examples/sec; 0.071 sec/batch)\n",
      "step 90, loss = 4.13 (1875.4 examples/sec; 0.068 sec/batch)\n",
      "step 100, loss = 4.32 (1808.7 examples/sec; 0.071 sec/batch)\n",
      "step 110, loss = 4.22 (1816.3 examples/sec; 0.070 sec/batch)\n",
      "step 120, loss = 4.00 (1886.1 examples/sec; 0.068 sec/batch)\n",
      "step 130, loss = 4.02 (1742.6 examples/sec; 0.073 sec/batch)\n",
      "step 140, loss = 3.92 (1908.3 examples/sec; 0.067 sec/batch)\n",
      "step 150, loss = 3.84 (1855.5 examples/sec; 0.069 sec/batch)\n",
      "step 160, loss = 4.03 (1806.8 examples/sec; 0.071 sec/batch)\n",
      "step 170, loss = 3.95 (1915.4 examples/sec; 0.067 sec/batch)\n",
      "step 180, loss = 3.73 (1884.6 examples/sec; 0.068 sec/batch)\n",
      "step 190, loss = 3.76 (1872.4 examples/sec; 0.068 sec/batch)\n",
      "step 200, loss = 3.79 (1862.9 examples/sec; 0.069 sec/batch)\n",
      "step 210, loss = 3.67 (1787.3 examples/sec; 0.072 sec/batch)\n",
      "step 220, loss = 3.93 (1824.2 examples/sec; 0.070 sec/batch)\n",
      "step 230, loss = 3.67 (1847.5 examples/sec; 0.069 sec/batch)\n",
      "step 240, loss = 3.87 (1824.2 examples/sec; 0.070 sec/batch)\n",
      "step 250, loss = 3.74 (1810.8 examples/sec; 0.071 sec/batch)\n",
      "step 260, loss = 3.60 (1900.5 examples/sec; 0.067 sec/batch)\n",
      "step 270, loss = 3.55 (1881.8 examples/sec; 0.068 sec/batch)\n",
      "step 280, loss = 3.65 (1850.0 examples/sec; 0.069 sec/batch)\n",
      "step 290, loss = 3.46 (1834.8 examples/sec; 0.070 sec/batch)\n",
      "step 300, loss = 3.45 (1849.6 examples/sec; 0.069 sec/batch)\n",
      "step 310, loss = 3.45 (1786.9 examples/sec; 0.072 sec/batch)\n",
      "step 320, loss = 3.44 (1736.7 examples/sec; 0.074 sec/batch)\n",
      "step 330, loss = 3.48 (1874.3 examples/sec; 0.068 sec/batch)\n",
      "step 340, loss = 3.46 (1811.4 examples/sec; 0.071 sec/batch)\n",
      "step 350, loss = 3.51 (1819.2 examples/sec; 0.070 sec/batch)\n",
      "step 360, loss = 3.41 (1842.1 examples/sec; 0.069 sec/batch)\n",
      "step 370, loss = 3.39 (1829.1 examples/sec; 0.070 sec/batch)\n",
      "step 380, loss = 3.68 (1886.7 examples/sec; 0.068 sec/batch)\n",
      "step 390, loss = 3.32 (1866.5 examples/sec; 0.069 sec/batch)\n",
      "step 400, loss = 3.30 (1869.8 examples/sec; 0.068 sec/batch)\n",
      "step 410, loss = 3.32 (1886.0 examples/sec; 0.068 sec/batch)\n",
      "step 420, loss = 3.27 (1910.7 examples/sec; 0.067 sec/batch)\n",
      "step 430, loss = 3.24 (1895.2 examples/sec; 0.068 sec/batch)\n",
      "step 440, loss = 3.24 (1802.5 examples/sec; 0.071 sec/batch)\n",
      "step 450, loss = 3.16 (1839.1 examples/sec; 0.070 sec/batch)\n",
      "step 460, loss = 3.22 (1877.9 examples/sec; 0.068 sec/batch)\n",
      "step 470, loss = 3.19 (1863.1 examples/sec; 0.069 sec/batch)\n",
      "step 480, loss = 3.24 (1801.5 examples/sec; 0.071 sec/batch)\n",
      "step 490, loss = 3.23 (1874.3 examples/sec; 0.068 sec/batch)\n",
      "step 500, loss = 3.21 (1864.5 examples/sec; 0.069 sec/batch)\n",
      "step 510, loss = 3.15 (1827.0 examples/sec; 0.070 sec/batch)\n",
      "step 520, loss = 3.20 (1917.4 examples/sec; 0.067 sec/batch)\n",
      "step 530, loss = 3.07 (1891.8 examples/sec; 0.068 sec/batch)\n",
      "step 540, loss = 2.94 (1892.5 examples/sec; 0.068 sec/batch)\n",
      "step 550, loss = 3.15 (1800.3 examples/sec; 0.071 sec/batch)\n",
      "step 560, loss = 3.08 (1849.1 examples/sec; 0.069 sec/batch)\n",
      "step 570, loss = 2.92 (1894.0 examples/sec; 0.068 sec/batch)\n",
      "step 580, loss = 2.87 (1873.3 examples/sec; 0.068 sec/batch)\n",
      "step 590, loss = 2.88 (1816.9 examples/sec; 0.070 sec/batch)\n",
      "step 600, loss = 3.05 (1951.6 examples/sec; 0.066 sec/batch)\n",
      "step 610, loss = 3.02 (1818.1 examples/sec; 0.070 sec/batch)\n",
      "step 620, loss = 2.99 (1985.5 examples/sec; 0.064 sec/batch)\n",
      "step 630, loss = 2.85 (1882.7 examples/sec; 0.068 sec/batch)\n",
      "step 640, loss = 2.92 (1834.0 examples/sec; 0.070 sec/batch)\n",
      "step 650, loss = 2.82 (1893.5 examples/sec; 0.068 sec/batch)\n",
      "step 660, loss = 2.81 (1877.4 examples/sec; 0.068 sec/batch)\n",
      "step 670, loss = 2.81 (1812.7 examples/sec; 0.071 sec/batch)\n",
      "step 680, loss = 2.77 (1828.9 examples/sec; 0.070 sec/batch)\n",
      "step 690, loss = 2.79 (1778.7 examples/sec; 0.072 sec/batch)\n",
      "step 700, loss = 2.72 (1882.5 examples/sec; 0.068 sec/batch)\n",
      "step 710, loss = 2.62 (1847.2 examples/sec; 0.069 sec/batch)\n",
      "step 720, loss = 2.76 (1830.1 examples/sec; 0.070 sec/batch)\n",
      "step 730, loss = 3.05 (1889.0 examples/sec; 0.068 sec/batch)\n",
      "step 740, loss = 2.77 (1884.8 examples/sec; 0.068 sec/batch)\n",
      "step 750, loss = 2.58 (1839.7 examples/sec; 0.070 sec/batch)\n",
      "step 760, loss = 2.61 (1905.8 examples/sec; 0.067 sec/batch)\n",
      "step 770, loss = 2.67 (1880.0 examples/sec; 0.068 sec/batch)\n",
      "step 780, loss = 2.61 (1866.5 examples/sec; 0.069 sec/batch)\n",
      "step 790, loss = 2.82 (1844.4 examples/sec; 0.069 sec/batch)\n",
      "step 800, loss = 2.58 (1850.0 examples/sec; 0.069 sec/batch)\n",
      "step 810, loss = 2.54 (1855.8 examples/sec; 0.069 sec/batch)\n",
      "step 820, loss = 2.65 (1951.3 examples/sec; 0.066 sec/batch)\n",
      "step 830, loss = 2.65 (1850.9 examples/sec; 0.069 sec/batch)\n",
      "step 840, loss = 2.64 (1901.1 examples/sec; 0.067 sec/batch)\n",
      "step 850, loss = 2.57 (1940.1 examples/sec; 0.066 sec/batch)\n",
      "step 860, loss = 2.46 (1867.6 examples/sec; 0.069 sec/batch)\n",
      "step 870, loss = 2.74 (1816.0 examples/sec; 0.070 sec/batch)\n",
      "step 880, loss = 2.64 (1960.5 examples/sec; 0.065 sec/batch)\n",
      "step 890, loss = 2.58 (1870.0 examples/sec; 0.068 sec/batch)\n",
      "step 900, loss = 2.40 (1874.9 examples/sec; 0.068 sec/batch)\n",
      "step 910, loss = 2.50 (1928.3 examples/sec; 0.066 sec/batch)\n",
      "step 920, loss = 2.36 (1871.3 examples/sec; 0.068 sec/batch)\n",
      "step 930, loss = 2.41 (1850.6 examples/sec; 0.069 sec/batch)\n",
      "step 940, loss = 2.57 (1892.3 examples/sec; 0.068 sec/batch)\n",
      "step 950, loss = 2.57 (1906.1 examples/sec; 0.067 sec/batch)\n",
      "step 960, loss = 2.66 (1883.6 examples/sec; 0.068 sec/batch)\n",
      "step 970, loss = 2.44 (1850.5 examples/sec; 0.069 sec/batch)\n",
      "step 980, loss = 2.46 (1840.8 examples/sec; 0.070 sec/batch)\n",
      "step 990, loss = 2.27 (1747.1 examples/sec; 0.073 sec/batch)\n",
      "step 1000, loss = 2.33 (1835.9 examples/sec; 0.070 sec/batch)\n",
      "step 1010, loss = 2.38 (1853.1 examples/sec; 0.069 sec/batch)\n",
      "step 1020, loss = 2.39 (1809.6 examples/sec; 0.071 sec/batch)\n",
      "step 1030, loss = 2.30 (1883.9 examples/sec; 0.068 sec/batch)\n",
      "step 1040, loss = 2.40 (1857.5 examples/sec; 0.069 sec/batch)\n",
      "step 1050, loss = 2.27 (1864.9 examples/sec; 0.069 sec/batch)\n",
      "step 1060, loss = 2.34 (1888.6 examples/sec; 0.068 sec/batch)\n",
      "step 1070, loss = 2.42 (1876.8 examples/sec; 0.068 sec/batch)\n",
      "step 1080, loss = 2.22 (1897.5 examples/sec; 0.067 sec/batch)\n",
      "step 1090, loss = 2.21 (1878.1 examples/sec; 0.068 sec/batch)\n",
      "step 1100, loss = 2.12 (1958.7 examples/sec; 0.065 sec/batch)\n",
      "step 1110, loss = 2.37 (1881.4 examples/sec; 0.068 sec/batch)\n",
      "step 1120, loss = 2.24 (1843.9 examples/sec; 0.069 sec/batch)\n",
      "step 1130, loss = 2.33 (1804.9 examples/sec; 0.071 sec/batch)\n",
      "step 1140, loss = 2.27 (1842.2 examples/sec; 0.069 sec/batch)\n",
      "step 1150, loss = 2.23 (1879.1 examples/sec; 0.068 sec/batch)\n",
      "step 1160, loss = 2.15 (1908.2 examples/sec; 0.067 sec/batch)\n",
      "step 1170, loss = 1.96 (1847.1 examples/sec; 0.069 sec/batch)\n",
      "step 1180, loss = 2.07 (1837.6 examples/sec; 0.070 sec/batch)\n",
      "step 1190, loss = 2.12 (1885.4 examples/sec; 0.068 sec/batch)\n",
      "step 1200, loss = 2.24 (1811.4 examples/sec; 0.071 sec/batch)\n",
      "step 1210, loss = 2.00 (1827.2 examples/sec; 0.070 sec/batch)\n",
      "step 1220, loss = 2.03 (1840.6 examples/sec; 0.070 sec/batch)\n",
      "step 1230, loss = 2.00 (1810.6 examples/sec; 0.071 sec/batch)\n",
      "step 1240, loss = 2.26 (1827.7 examples/sec; 0.070 sec/batch)\n",
      "step 1250, loss = 2.10 (1828.0 examples/sec; 0.070 sec/batch)\n",
      "step 1260, loss = 2.37 (1892.0 examples/sec; 0.068 sec/batch)\n",
      "step 1270, loss = 2.14 (1766.5 examples/sec; 0.072 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1280, loss = 2.21 (1778.2 examples/sec; 0.072 sec/batch)\n",
      "step 1290, loss = 2.08 (1868.0 examples/sec; 0.069 sec/batch)\n",
      "step 1300, loss = 2.02 (1775.9 examples/sec; 0.072 sec/batch)\n",
      "step 1310, loss = 2.09 (1841.0 examples/sec; 0.070 sec/batch)\n",
      "step 1320, loss = 1.87 (1861.1 examples/sec; 0.069 sec/batch)\n",
      "step 1330, loss = 1.96 (1845.0 examples/sec; 0.069 sec/batch)\n",
      "step 1340, loss = 2.02 (1974.6 examples/sec; 0.065 sec/batch)\n",
      "step 1350, loss = 1.95 (1930.1 examples/sec; 0.066 sec/batch)\n",
      "step 1360, loss = 2.04 (1894.9 examples/sec; 0.068 sec/batch)\n",
      "step 1370, loss = 1.78 (1902.7 examples/sec; 0.067 sec/batch)\n",
      "step 1380, loss = 1.86 (1890.3 examples/sec; 0.068 sec/batch)\n",
      "step 1390, loss = 2.02 (1760.4 examples/sec; 0.073 sec/batch)\n",
      "step 1400, loss = 1.83 (1766.5 examples/sec; 0.072 sec/batch)\n",
      "step 1410, loss = 1.95 (1812.6 examples/sec; 0.071 sec/batch)\n",
      "step 1420, loss = 1.92 (1851.5 examples/sec; 0.069 sec/batch)\n",
      "step 1430, loss = 1.86 (1887.0 examples/sec; 0.068 sec/batch)\n",
      "step 1440, loss = 2.05 (1832.3 examples/sec; 0.070 sec/batch)\n",
      "step 1450, loss = 2.01 (1850.4 examples/sec; 0.069 sec/batch)\n",
      "step 1460, loss = 1.76 (1923.7 examples/sec; 0.067 sec/batch)\n",
      "step 1470, loss = 1.69 (1865.9 examples/sec; 0.069 sec/batch)\n",
      "step 1480, loss = 1.85 (1878.6 examples/sec; 0.068 sec/batch)\n",
      "step 1490, loss = 1.88 (1942.3 examples/sec; 0.066 sec/batch)\n",
      "step 1500, loss = 1.86 (1794.9 examples/sec; 0.071 sec/batch)\n",
      "step 1510, loss = 1.88 (1862.3 examples/sec; 0.069 sec/batch)\n",
      "step 1520, loss = 1.78 (1847.1 examples/sec; 0.069 sec/batch)\n",
      "step 1530, loss = 1.80 (1848.0 examples/sec; 0.069 sec/batch)\n",
      "step 1540, loss = 1.76 (1899.0 examples/sec; 0.067 sec/batch)\n",
      "step 1550, loss = 1.84 (1839.2 examples/sec; 0.070 sec/batch)\n",
      "step 1560, loss = 1.83 (1807.7 examples/sec; 0.071 sec/batch)\n",
      "step 1570, loss = 1.77 (1839.4 examples/sec; 0.070 sec/batch)\n",
      "step 1580, loss = 1.76 (1903.5 examples/sec; 0.067 sec/batch)\n",
      "step 1590, loss = 1.84 (1875.3 examples/sec; 0.068 sec/batch)\n",
      "step 1600, loss = 1.76 (1834.6 examples/sec; 0.070 sec/batch)\n",
      "step 1610, loss = 1.83 (1829.8 examples/sec; 0.070 sec/batch)\n",
      "step 1620, loss = 1.69 (1881.5 examples/sec; 0.068 sec/batch)\n",
      "step 1630, loss = 1.77 (1869.7 examples/sec; 0.068 sec/batch)\n",
      "step 1640, loss = 1.64 (1799.5 examples/sec; 0.071 sec/batch)\n",
      "step 1650, loss = 1.65 (1785.8 examples/sec; 0.072 sec/batch)\n",
      "step 1660, loss = 1.66 (1965.2 examples/sec; 0.065 sec/batch)\n",
      "step 1670, loss = 1.90 (1805.8 examples/sec; 0.071 sec/batch)\n",
      "step 1680, loss = 1.59 (1841.2 examples/sec; 0.070 sec/batch)\n",
      "step 1690, loss = 1.58 (1890.5 examples/sec; 0.068 sec/batch)\n",
      "step 1700, loss = 1.73 (1865.3 examples/sec; 0.069 sec/batch)\n",
      "step 1710, loss = 1.66 (1828.3 examples/sec; 0.070 sec/batch)\n",
      "step 1720, loss = 1.71 (1810.7 examples/sec; 0.071 sec/batch)\n",
      "step 1730, loss = 1.64 (1893.3 examples/sec; 0.068 sec/batch)\n",
      "step 1740, loss = 2.04 (1847.7 examples/sec; 0.069 sec/batch)\n",
      "step 1750, loss = 1.68 (1858.4 examples/sec; 0.069 sec/batch)\n",
      "step 1760, loss = 1.77 (1834.7 examples/sec; 0.070 sec/batch)\n",
      "step 1770, loss = 1.69 (1857.6 examples/sec; 0.069 sec/batch)\n",
      "step 1780, loss = 1.55 (1801.4 examples/sec; 0.071 sec/batch)\n",
      "step 1790, loss = 1.86 (1850.2 examples/sec; 0.069 sec/batch)\n",
      "step 1800, loss = 1.79 (1848.2 examples/sec; 0.069 sec/batch)\n",
      "step 1810, loss = 1.75 (1917.1 examples/sec; 0.067 sec/batch)\n",
      "step 1820, loss = 1.56 (1855.0 examples/sec; 0.069 sec/batch)\n",
      "step 1830, loss = 1.64 (1884.5 examples/sec; 0.068 sec/batch)\n",
      "step 1840, loss = 1.50 (1898.8 examples/sec; 0.067 sec/batch)\n",
      "step 1850, loss = 1.50 (1923.0 examples/sec; 0.067 sec/batch)\n",
      "step 1860, loss = 1.80 (1864.1 examples/sec; 0.069 sec/batch)\n",
      "step 1870, loss = 1.51 (1838.5 examples/sec; 0.070 sec/batch)\n",
      "step 1880, loss = 1.57 (1841.2 examples/sec; 0.070 sec/batch)\n",
      "step 1890, loss = 1.60 (1807.8 examples/sec; 0.071 sec/batch)\n",
      "step 1900, loss = 1.84 (1921.5 examples/sec; 0.067 sec/batch)\n",
      "step 1910, loss = 1.40 (1840.7 examples/sec; 0.070 sec/batch)\n",
      "step 1920, loss = 1.47 (1871.7 examples/sec; 0.068 sec/batch)\n",
      "step 1930, loss = 1.53 (1894.2 examples/sec; 0.068 sec/batch)\n",
      "step 1940, loss = 1.42 (1868.4 examples/sec; 0.069 sec/batch)\n",
      "step 1950, loss = 1.69 (1792.0 examples/sec; 0.071 sec/batch)\n",
      "step 1960, loss = 1.50 (1823.5 examples/sec; 0.070 sec/batch)\n",
      "step 1970, loss = 1.60 (1837.6 examples/sec; 0.070 sec/batch)\n",
      "step 1980, loss = 1.52 (1903.0 examples/sec; 0.067 sec/batch)\n",
      "step 1990, loss = 1.59 (1885.9 examples/sec; 0.068 sec/batch)\n",
      "step 2000, loss = 1.52 (1817.0 examples/sec; 0.070 sec/batch)\n",
      "step 2010, loss = 1.80 (1883.0 examples/sec; 0.068 sec/batch)\n",
      "step 2020, loss = 1.51 (1798.6 examples/sec; 0.071 sec/batch)\n",
      "step 2030, loss = 1.52 (1736.4 examples/sec; 0.074 sec/batch)\n",
      "step 2040, loss = 1.37 (1904.7 examples/sec; 0.067 sec/batch)\n",
      "step 2050, loss = 1.44 (1827.7 examples/sec; 0.070 sec/batch)\n",
      "step 2060, loss = 1.95 (1812.6 examples/sec; 0.071 sec/batch)\n",
      "step 2070, loss = 1.64 (1876.5 examples/sec; 0.068 sec/batch)\n",
      "step 2080, loss = 1.70 (1850.0 examples/sec; 0.069 sec/batch)\n",
      "step 2090, loss = 1.54 (1895.5 examples/sec; 0.068 sec/batch)\n",
      "step 2100, loss = 1.44 (1867.3 examples/sec; 0.069 sec/batch)\n",
      "step 2110, loss = 1.42 (1879.2 examples/sec; 0.068 sec/batch)\n",
      "step 2120, loss = 1.60 (1906.5 examples/sec; 0.067 sec/batch)\n",
      "step 2130, loss = 1.57 (1927.0 examples/sec; 0.066 sec/batch)\n",
      "step 2140, loss = 1.55 (1832.3 examples/sec; 0.070 sec/batch)\n",
      "step 2150, loss = 1.59 (1813.4 examples/sec; 0.071 sec/batch)\n",
      "step 2160, loss = 1.45 (1948.5 examples/sec; 0.066 sec/batch)\n",
      "step 2170, loss = 1.38 (1844.9 examples/sec; 0.069 sec/batch)\n",
      "step 2180, loss = 1.28 (1817.2 examples/sec; 0.070 sec/batch)\n",
      "step 2190, loss = 1.34 (1728.4 examples/sec; 0.074 sec/batch)\n",
      "step 2200, loss = 1.47 (1925.1 examples/sec; 0.066 sec/batch)\n",
      "step 2210, loss = 1.38 (1905.0 examples/sec; 0.067 sec/batch)\n",
      "step 2220, loss = 1.48 (1867.8 examples/sec; 0.069 sec/batch)\n",
      "step 2230, loss = 1.54 (1796.8 examples/sec; 0.071 sec/batch)\n",
      "step 2240, loss = 1.37 (1761.6 examples/sec; 0.073 sec/batch)\n",
      "step 2250, loss = 1.41 (1834.3 examples/sec; 0.070 sec/batch)\n",
      "step 2260, loss = 1.45 (1854.5 examples/sec; 0.069 sec/batch)\n",
      "step 2270, loss = 1.31 (1796.1 examples/sec; 0.071 sec/batch)\n",
      "step 2280, loss = 1.28 (1833.4 examples/sec; 0.070 sec/batch)\n",
      "step 2290, loss = 1.29 (1847.9 examples/sec; 0.069 sec/batch)\n",
      "step 2300, loss = 1.50 (1805.8 examples/sec; 0.071 sec/batch)\n",
      "step 2310, loss = 1.40 (2017.8 examples/sec; 0.063 sec/batch)\n",
      "step 2320, loss = 1.29 (1844.2 examples/sec; 0.069 sec/batch)\n",
      "step 2330, loss = 1.45 (1787.0 examples/sec; 0.072 sec/batch)\n",
      "step 2340, loss = 1.50 (1832.0 examples/sec; 0.070 sec/batch)\n",
      "step 2350, loss = 1.30 (1856.2 examples/sec; 0.069 sec/batch)\n",
      "step 2360, loss = 1.32 (1805.4 examples/sec; 0.071 sec/batch)\n",
      "step 2370, loss = 1.44 (1803.4 examples/sec; 0.071 sec/batch)\n",
      "step 2380, loss = 1.41 (1845.8 examples/sec; 0.069 sec/batch)\n",
      "step 2390, loss = 1.29 (1883.7 examples/sec; 0.068 sec/batch)\n",
      "step 2400, loss = 1.48 (1823.6 examples/sec; 0.070 sec/batch)\n",
      "step 2410, loss = 1.49 (1855.1 examples/sec; 0.069 sec/batch)\n",
      "step 2420, loss = 1.56 (1828.5 examples/sec; 0.070 sec/batch)\n",
      "step 2430, loss = 1.21 (1904.1 examples/sec; 0.067 sec/batch)\n",
      "step 2440, loss = 1.49 (1839.1 examples/sec; 0.070 sec/batch)\n",
      "step 2450, loss = 1.41 (1875.7 examples/sec; 0.068 sec/batch)\n",
      "step 2460, loss = 1.32 (1910.0 examples/sec; 0.067 sec/batch)\n",
      "step 2470, loss = 1.27 (1873.4 examples/sec; 0.068 sec/batch)\n",
      "step 2480, loss = 1.41 (1894.9 examples/sec; 0.068 sec/batch)\n",
      "step 2490, loss = 1.31 (1879.0 examples/sec; 0.068 sec/batch)\n",
      "step 2500, loss = 1.32 (1864.9 examples/sec; 0.069 sec/batch)\n",
      "step 2510, loss = 1.61 (1899.7 examples/sec; 0.067 sec/batch)\n",
      "step 2520, loss = 1.25 (1796.3 examples/sec; 0.071 sec/batch)\n",
      "step 2530, loss = 1.32 (1957.2 examples/sec; 0.065 sec/batch)\n",
      "step 2540, loss = 1.27 (1909.5 examples/sec; 0.067 sec/batch)\n",
      "step 2550, loss = 1.28 (1867.5 examples/sec; 0.069 sec/batch)\n",
      "step 2560, loss = 1.32 (1844.0 examples/sec; 0.069 sec/batch)\n",
      "step 2570, loss = 1.40 (1898.1 examples/sec; 0.067 sec/batch)\n",
      "step 2580, loss = 1.33 (1822.3 examples/sec; 0.070 sec/batch)\n",
      "step 2590, loss = 1.32 (1768.9 examples/sec; 0.072 sec/batch)\n",
      "step 2600, loss = 1.28 (1770.7 examples/sec; 0.072 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2610, loss = 1.33 (1901.1 examples/sec; 0.067 sec/batch)\n",
      "step 2620, loss = 1.42 (1848.0 examples/sec; 0.069 sec/batch)\n",
      "step 2630, loss = 1.09 (1792.0 examples/sec; 0.071 sec/batch)\n",
      "step 2640, loss = 1.41 (1781.9 examples/sec; 0.072 sec/batch)\n",
      "step 2650, loss = 1.17 (1832.6 examples/sec; 0.070 sec/batch)\n",
      "step 2660, loss = 1.35 (1826.6 examples/sec; 0.070 sec/batch)\n",
      "step 2670, loss = 1.26 (1835.6 examples/sec; 0.070 sec/batch)\n",
      "step 2680, loss = 1.35 (1812.1 examples/sec; 0.071 sec/batch)\n",
      "step 2690, loss = 1.36 (1795.1 examples/sec; 0.071 sec/batch)\n",
      "step 2700, loss = 1.48 (1852.6 examples/sec; 0.069 sec/batch)\n",
      "step 2710, loss = 1.50 (1906.9 examples/sec; 0.067 sec/batch)\n",
      "step 2720, loss = 1.22 (1888.6 examples/sec; 0.068 sec/batch)\n",
      "step 2730, loss = 1.40 (1895.2 examples/sec; 0.068 sec/batch)\n",
      "step 2740, loss = 1.14 (1888.6 examples/sec; 0.068 sec/batch)\n",
      "step 2750, loss = 1.46 (1784.5 examples/sec; 0.072 sec/batch)\n",
      "step 2760, loss = 1.20 (1822.9 examples/sec; 0.070 sec/batch)\n",
      "step 2770, loss = 1.24 (1869.3 examples/sec; 0.068 sec/batch)\n",
      "step 2780, loss = 1.28 (1899.7 examples/sec; 0.067 sec/batch)\n",
      "step 2790, loss = 1.39 (1895.2 examples/sec; 0.068 sec/batch)\n",
      "step 2800, loss = 1.21 (1835.3 examples/sec; 0.070 sec/batch)\n",
      "step 2810, loss = 1.36 (1829.8 examples/sec; 0.070 sec/batch)\n",
      "step 2820, loss = 1.37 (1921.5 examples/sec; 0.067 sec/batch)\n",
      "step 2830, loss = 1.46 (1950.0 examples/sec; 0.066 sec/batch)\n",
      "step 2840, loss = 1.33 (1888.2 examples/sec; 0.068 sec/batch)\n",
      "step 2850, loss = 1.24 (1876.1 examples/sec; 0.068 sec/batch)\n",
      "step 2860, loss = 1.15 (1820.0 examples/sec; 0.070 sec/batch)\n",
      "step 2870, loss = 1.32 (1924.9 examples/sec; 0.066 sec/batch)\n",
      "step 2880, loss = 1.24 (1794.6 examples/sec; 0.071 sec/batch)\n",
      "step 2890, loss = 1.18 (1856.9 examples/sec; 0.069 sec/batch)\n",
      "step 2900, loss = 1.28 (1875.0 examples/sec; 0.068 sec/batch)\n",
      "step 2910, loss = 1.27 (1747.9 examples/sec; 0.073 sec/batch)\n",
      "step 2920, loss = 1.09 (1911.1 examples/sec; 0.067 sec/batch)\n",
      "step 2930, loss = 1.22 (1793.0 examples/sec; 0.071 sec/batch)\n",
      "step 2940, loss = 1.25 (1847.0 examples/sec; 0.069 sec/batch)\n",
      "step 2950, loss = 1.38 (1850.3 examples/sec; 0.069 sec/batch)\n",
      "step 2960, loss = 1.37 (1866.5 examples/sec; 0.069 sec/batch)\n",
      "step 2970, loss = 1.21 (1719.0 examples/sec; 0.074 sec/batch)\n",
      "step 2980, loss = 1.45 (1860.3 examples/sec; 0.069 sec/batch)\n",
      "step 2990, loss = 1.16 (1809.1 examples/sec; 0.071 sec/batch)\n",
      "step 3000, loss = 1.27 (1813.6 examples/sec; 0.071 sec/batch)\n",
      "step 3010, loss = 1.15 (1888.8 examples/sec; 0.068 sec/batch)\n",
      "step 3020, loss = 1.25 (1880.6 examples/sec; 0.068 sec/batch)\n",
      "step 3030, loss = 1.23 (1785.3 examples/sec; 0.072 sec/batch)\n",
      "step 3040, loss = 1.36 (1863.6 examples/sec; 0.069 sec/batch)\n",
      "step 3050, loss = 1.17 (1864.1 examples/sec; 0.069 sec/batch)\n",
      "step 3060, loss = 1.38 (1930.4 examples/sec; 0.066 sec/batch)\n",
      "step 3070, loss = 1.16 (1853.2 examples/sec; 0.069 sec/batch)\n",
      "step 3080, loss = 1.16 (1883.2 examples/sec; 0.068 sec/batch)\n",
      "step 3090, loss = 1.16 (1775.9 examples/sec; 0.072 sec/batch)\n",
      "step 3100, loss = 1.22 (1840.2 examples/sec; 0.070 sec/batch)\n",
      "step 3110, loss = 1.24 (1712.5 examples/sec; 0.075 sec/batch)\n",
      "step 3120, loss = 1.12 (1832.6 examples/sec; 0.070 sec/batch)\n",
      "step 3130, loss = 1.23 (1720.5 examples/sec; 0.074 sec/batch)\n",
      "step 3140, loss = 1.27 (1853.2 examples/sec; 0.069 sec/batch)\n",
      "step 3150, loss = 1.26 (1830.3 examples/sec; 0.070 sec/batch)\n",
      "step 3160, loss = 1.06 (1949.7 examples/sec; 0.066 sec/batch)\n",
      "step 3170, loss = 1.04 (1799.8 examples/sec; 0.071 sec/batch)\n",
      "step 3180, loss = 1.14 (1914.0 examples/sec; 0.067 sec/batch)\n",
      "step 3190, loss = 1.34 (1860.7 examples/sec; 0.069 sec/batch)\n",
      "step 3200, loss = 1.12 (1888.2 examples/sec; 0.068 sec/batch)\n",
      "step 3210, loss = 1.06 (1820.2 examples/sec; 0.070 sec/batch)\n",
      "step 3220, loss = 0.91 (1829.9 examples/sec; 0.070 sec/batch)\n",
      "step 3230, loss = 1.22 (1813.8 examples/sec; 0.071 sec/batch)\n",
      "step 3240, loss = 1.26 (1862.4 examples/sec; 0.069 sec/batch)\n",
      "step 3250, loss = 1.23 (1891.5 examples/sec; 0.068 sec/batch)\n",
      "step 3260, loss = 1.01 (1884.8 examples/sec; 0.068 sec/batch)\n",
      "step 3270, loss = 1.12 (1837.5 examples/sec; 0.070 sec/batch)\n",
      "step 3280, loss = 1.08 (1900.0 examples/sec; 0.067 sec/batch)\n",
      "step 3290, loss = 1.16 (1851.3 examples/sec; 0.069 sec/batch)\n",
      "step 3300, loss = 1.02 (1797.6 examples/sec; 0.071 sec/batch)\n",
      "step 3310, loss = 1.17 (1903.6 examples/sec; 0.067 sec/batch)\n",
      "step 3320, loss = 1.10 (1798.9 examples/sec; 0.071 sec/batch)\n",
      "step 3330, loss = 1.18 (1840.9 examples/sec; 0.070 sec/batch)\n",
      "step 3340, loss = 1.32 (1889.9 examples/sec; 0.068 sec/batch)\n",
      "step 3350, loss = 0.93 (1898.0 examples/sec; 0.067 sec/batch)\n",
      "step 3360, loss = 1.15 (1839.5 examples/sec; 0.070 sec/batch)\n",
      "step 3370, loss = 0.99 (1864.7 examples/sec; 0.069 sec/batch)\n",
      "step 3380, loss = 1.15 (1751.2 examples/sec; 0.073 sec/batch)\n",
      "step 3390, loss = 1.14 (1859.1 examples/sec; 0.069 sec/batch)\n",
      "step 3400, loss = 1.06 (1994.2 examples/sec; 0.064 sec/batch)\n",
      "step 3410, loss = 1.10 (1842.3 examples/sec; 0.069 sec/batch)\n",
      "step 3420, loss = 1.01 (1900.3 examples/sec; 0.067 sec/batch)\n",
      "step 3430, loss = 0.99 (1843.7 examples/sec; 0.069 sec/batch)\n",
      "step 3440, loss = 1.08 (1787.3 examples/sec; 0.072 sec/batch)\n",
      "step 3450, loss = 1.04 (1876.6 examples/sec; 0.068 sec/batch)\n",
      "step 3460, loss = 1.04 (1780.3 examples/sec; 0.072 sec/batch)\n",
      "step 3470, loss = 1.16 (1780.9 examples/sec; 0.072 sec/batch)\n",
      "step 3480, loss = 1.30 (1934.3 examples/sec; 0.066 sec/batch)\n",
      "step 3490, loss = 1.22 (1877.5 examples/sec; 0.068 sec/batch)\n",
      "step 3500, loss = 1.24 (1808.1 examples/sec; 0.071 sec/batch)\n",
      "step 3510, loss = 1.17 (1844.1 examples/sec; 0.069 sec/batch)\n",
      "step 3520, loss = 0.97 (1878.6 examples/sec; 0.068 sec/batch)\n",
      "step 3530, loss = 0.94 (1875.1 examples/sec; 0.068 sec/batch)\n",
      "step 3540, loss = 1.02 (1837.9 examples/sec; 0.070 sec/batch)\n",
      "step 3550, loss = 1.03 (1811.9 examples/sec; 0.071 sec/batch)\n",
      "step 3560, loss = 0.90 (1804.7 examples/sec; 0.071 sec/batch)\n",
      "step 3570, loss = 1.14 (1846.7 examples/sec; 0.069 sec/batch)\n",
      "step 3580, loss = 1.04 (1717.2 examples/sec; 0.075 sec/batch)\n",
      "step 3590, loss = 1.16 (1857.5 examples/sec; 0.069 sec/batch)\n",
      "step 3600, loss = 1.11 (1823.0 examples/sec; 0.070 sec/batch)\n",
      "step 3610, loss = 1.24 (1852.5 examples/sec; 0.069 sec/batch)\n",
      "step 3620, loss = 1.17 (1791.6 examples/sec; 0.071 sec/batch)\n",
      "step 3630, loss = 0.91 (1817.2 examples/sec; 0.070 sec/batch)\n",
      "step 3640, loss = 1.10 (1768.7 examples/sec; 0.072 sec/batch)\n",
      "step 3650, loss = 0.99 (1899.9 examples/sec; 0.067 sec/batch)\n",
      "step 3660, loss = 1.16 (1840.6 examples/sec; 0.070 sec/batch)\n",
      "step 3670, loss = 0.96 (1768.5 examples/sec; 0.072 sec/batch)\n",
      "step 3680, loss = 0.97 (1825.7 examples/sec; 0.070 sec/batch)\n",
      "step 3690, loss = 0.94 (1787.1 examples/sec; 0.072 sec/batch)\n",
      "step 3700, loss = 1.01 (1783.5 examples/sec; 0.072 sec/batch)\n",
      "step 3710, loss = 1.06 (1783.7 examples/sec; 0.072 sec/batch)\n",
      "step 3720, loss = 1.01 (1745.8 examples/sec; 0.073 sec/batch)\n",
      "step 3730, loss = 0.99 (1799.7 examples/sec; 0.071 sec/batch)\n",
      "step 3740, loss = 1.14 (1817.5 examples/sec; 0.070 sec/batch)\n",
      "step 3750, loss = 1.01 (1854.1 examples/sec; 0.069 sec/batch)\n",
      "step 3760, loss = 0.97 (1873.4 examples/sec; 0.068 sec/batch)\n",
      "step 3770, loss = 1.05 (1827.3 examples/sec; 0.070 sec/batch)\n",
      "step 3780, loss = 0.86 (1928.4 examples/sec; 0.066 sec/batch)\n",
      "step 3790, loss = 1.09 (1807.3 examples/sec; 0.071 sec/batch)\n",
      "step 3800, loss = 1.00 (1779.6 examples/sec; 0.072 sec/batch)\n",
      "step 3810, loss = 0.96 (1783.5 examples/sec; 0.072 sec/batch)\n",
      "step 3820, loss = 0.84 (1832.3 examples/sec; 0.070 sec/batch)\n",
      "step 3830, loss = 0.98 (1815.0 examples/sec; 0.071 sec/batch)\n",
      "step 3840, loss = 0.94 (1802.9 examples/sec; 0.071 sec/batch)\n",
      "step 3850, loss = 1.11 (1856.9 examples/sec; 0.069 sec/batch)\n",
      "step 3860, loss = 0.87 (1860.6 examples/sec; 0.069 sec/batch)\n",
      "step 3870, loss = 1.33 (1840.8 examples/sec; 0.070 sec/batch)\n",
      "step 3880, loss = 1.02 (1796.0 examples/sec; 0.071 sec/batch)\n",
      "step 3890, loss = 1.11 (1892.3 examples/sec; 0.068 sec/batch)\n",
      "step 3900, loss = 1.06 (1835.2 examples/sec; 0.070 sec/batch)\n",
      "step 3910, loss = 0.98 (1786.3 examples/sec; 0.072 sec/batch)\n",
      "step 3920, loss = 1.11 (1879.0 examples/sec; 0.068 sec/batch)\n",
      "step 3930, loss = 0.95 (1837.0 examples/sec; 0.070 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3940, loss = 0.96 (1836.4 examples/sec; 0.070 sec/batch)\n",
      "step 3950, loss = 0.93 (1861.0 examples/sec; 0.069 sec/batch)\n",
      "step 3960, loss = 1.01 (1979.7 examples/sec; 0.065 sec/batch)\n",
      "step 3970, loss = 1.06 (1831.5 examples/sec; 0.070 sec/batch)\n",
      "step 3980, loss = 0.93 (1831.1 examples/sec; 0.070 sec/batch)\n",
      "step 3990, loss = 0.99 (1814.0 examples/sec; 0.071 sec/batch)\n",
      "step 4000, loss = 0.99 (1813.0 examples/sec; 0.071 sec/batch)\n",
      "step 4010, loss = 0.89 (1812.9 examples/sec; 0.071 sec/batch)\n",
      "step 4020, loss = 0.93 (1809.4 examples/sec; 0.071 sec/batch)\n",
      "step 4030, loss = 0.94 (1795.8 examples/sec; 0.071 sec/batch)\n",
      "step 4040, loss = 0.88 (1835.9 examples/sec; 0.070 sec/batch)\n",
      "step 4050, loss = 0.91 (1824.8 examples/sec; 0.070 sec/batch)\n",
      "step 4060, loss = 1.13 (1843.1 examples/sec; 0.069 sec/batch)\n",
      "step 4070, loss = 0.81 (1904.4 examples/sec; 0.067 sec/batch)\n",
      "step 4080, loss = 1.12 (1762.8 examples/sec; 0.073 sec/batch)\n",
      "step 4090, loss = 0.84 (1868.6 examples/sec; 0.068 sec/batch)\n",
      "step 4100, loss = 1.14 (1817.5 examples/sec; 0.070 sec/batch)\n",
      "step 4110, loss = 1.04 (1812.6 examples/sec; 0.071 sec/batch)\n",
      "step 4120, loss = 1.07 (1889.4 examples/sec; 0.068 sec/batch)\n",
      "step 4130, loss = 0.86 (1756.6 examples/sec; 0.073 sec/batch)\n",
      "step 4140, loss = 0.94 (1800.6 examples/sec; 0.071 sec/batch)\n",
      "step 4150, loss = 0.95 (1887.5 examples/sec; 0.068 sec/batch)\n",
      "step 4160, loss = 1.02 (1909.2 examples/sec; 0.067 sec/batch)\n",
      "step 4170, loss = 0.98 (1761.0 examples/sec; 0.073 sec/batch)\n",
      "step 4180, loss = 0.86 (1832.9 examples/sec; 0.070 sec/batch)\n",
      "step 4190, loss = 0.98 (1825.0 examples/sec; 0.070 sec/batch)\n",
      "step 4200, loss = 0.94 (1919.4 examples/sec; 0.067 sec/batch)\n",
      "step 4210, loss = 1.00 (1816.4 examples/sec; 0.070 sec/batch)\n",
      "step 4220, loss = 0.97 (1871.2 examples/sec; 0.068 sec/batch)\n",
      "step 4230, loss = 0.95 (1852.6 examples/sec; 0.069 sec/batch)\n",
      "step 4240, loss = 0.93 (1799.9 examples/sec; 0.071 sec/batch)\n",
      "step 4250, loss = 0.89 (1838.0 examples/sec; 0.070 sec/batch)\n",
      "step 4260, loss = 0.92 (1877.9 examples/sec; 0.068 sec/batch)\n",
      "step 4270, loss = 0.98 (1856.1 examples/sec; 0.069 sec/batch)\n",
      "step 4280, loss = 1.13 (1806.5 examples/sec; 0.071 sec/batch)\n",
      "step 4290, loss = 1.04 (1846.6 examples/sec; 0.069 sec/batch)\n",
      "step 4300, loss = 1.03 (1928.7 examples/sec; 0.066 sec/batch)\n",
      "step 4310, loss = 0.83 (1819.7 examples/sec; 0.070 sec/batch)\n",
      "step 4320, loss = 1.06 (1806.2 examples/sec; 0.071 sec/batch)\n",
      "step 4330, loss = 1.01 (1913.6 examples/sec; 0.067 sec/batch)\n",
      "step 4340, loss = 1.10 (1863.0 examples/sec; 0.069 sec/batch)\n",
      "step 4350, loss = 0.88 (1835.5 examples/sec; 0.070 sec/batch)\n",
      "step 4360, loss = 0.85 (1863.8 examples/sec; 0.069 sec/batch)\n",
      "step 4370, loss = 1.19 (1856.9 examples/sec; 0.069 sec/batch)\n",
      "step 4380, loss = 1.08 (1800.3 examples/sec; 0.071 sec/batch)\n",
      "step 4390, loss = 1.03 (1729.4 examples/sec; 0.074 sec/batch)\n",
      "step 4400, loss = 0.88 (1935.1 examples/sec; 0.066 sec/batch)\n",
      "step 4410, loss = 0.94 (1857.9 examples/sec; 0.069 sec/batch)\n",
      "step 4420, loss = 0.96 (1851.7 examples/sec; 0.069 sec/batch)\n",
      "step 4430, loss = 1.04 (1916.5 examples/sec; 0.067 sec/batch)\n",
      "step 4440, loss = 0.90 (1817.4 examples/sec; 0.070 sec/batch)\n",
      "step 4450, loss = 1.04 (1856.0 examples/sec; 0.069 sec/batch)\n",
      "step 4460, loss = 0.93 (1875.8 examples/sec; 0.068 sec/batch)\n",
      "step 4470, loss = 1.03 (1801.7 examples/sec; 0.071 sec/batch)\n",
      "step 4480, loss = 0.95 (1931.5 examples/sec; 0.066 sec/batch)\n",
      "step 4490, loss = 0.95 (1860.3 examples/sec; 0.069 sec/batch)\n",
      "step 4500, loss = 1.03 (1931.1 examples/sec; 0.066 sec/batch)\n",
      "step 4510, loss = 1.15 (1901.5 examples/sec; 0.067 sec/batch)\n",
      "step 4520, loss = 1.02 (1832.7 examples/sec; 0.070 sec/batch)\n",
      "step 4530, loss = 0.97 (1797.1 examples/sec; 0.071 sec/batch)\n",
      "step 4540, loss = 0.98 (1823.6 examples/sec; 0.070 sec/batch)\n",
      "step 4550, loss = 0.98 (1823.0 examples/sec; 0.070 sec/batch)\n",
      "step 4560, loss = 1.10 (1784.4 examples/sec; 0.072 sec/batch)\n",
      "step 4570, loss = 0.84 (1786.9 examples/sec; 0.072 sec/batch)\n",
      "step 4580, loss = 1.01 (1894.0 examples/sec; 0.068 sec/batch)\n",
      "step 4590, loss = 0.97 (2066.3 examples/sec; 0.062 sec/batch)\n",
      "step 4600, loss = 0.97 (1916.9 examples/sec; 0.067 sec/batch)\n",
      "step 4610, loss = 0.87 (1850.2 examples/sec; 0.069 sec/batch)\n",
      "step 4620, loss = 0.83 (1829.2 examples/sec; 0.070 sec/batch)\n",
      "step 4630, loss = 0.94 (1883.0 examples/sec; 0.068 sec/batch)\n",
      "step 4640, loss = 0.93 (1866.3 examples/sec; 0.069 sec/batch)\n",
      "step 4650, loss = 0.92 (1974.0 examples/sec; 0.065 sec/batch)\n",
      "step 4660, loss = 1.00 (1770.9 examples/sec; 0.072 sec/batch)\n",
      "step 4670, loss = 0.83 (1835.9 examples/sec; 0.070 sec/batch)\n",
      "step 4680, loss = 0.81 (1915.7 examples/sec; 0.067 sec/batch)\n",
      "step 4690, loss = 1.09 (1892.7 examples/sec; 0.068 sec/batch)\n",
      "step 4700, loss = 0.96 (1866.5 examples/sec; 0.069 sec/batch)\n",
      "step 4710, loss = 1.12 (1837.8 examples/sec; 0.070 sec/batch)\n",
      "step 4720, loss = 0.91 (1877.7 examples/sec; 0.068 sec/batch)\n",
      "step 4730, loss = 0.95 (1790.1 examples/sec; 0.072 sec/batch)\n",
      "step 4740, loss = 0.98 (1873.0 examples/sec; 0.068 sec/batch)\n",
      "step 4750, loss = 0.83 (1829.4 examples/sec; 0.070 sec/batch)\n",
      "step 4760, loss = 1.11 (1772.2 examples/sec; 0.072 sec/batch)\n",
      "step 4770, loss = 1.13 (1879.9 examples/sec; 0.068 sec/batch)\n",
      "step 4780, loss = 0.83 (1831.3 examples/sec; 0.070 sec/batch)\n",
      "step 4790, loss = 1.07 (1802.1 examples/sec; 0.071 sec/batch)\n",
      "step 4800, loss = 1.02 (1857.2 examples/sec; 0.069 sec/batch)\n",
      "step 4810, loss = 1.19 (1918.2 examples/sec; 0.067 sec/batch)\n",
      "step 4820, loss = 0.97 (1823.4 examples/sec; 0.070 sec/batch)\n",
      "step 4830, loss = 0.79 (1824.1 examples/sec; 0.070 sec/batch)\n",
      "step 4840, loss = 0.98 (1756.0 examples/sec; 0.073 sec/batch)\n",
      "step 4850, loss = 0.89 (1945.8 examples/sec; 0.066 sec/batch)\n",
      "step 4860, loss = 0.82 (1872.1 examples/sec; 0.068 sec/batch)\n",
      "step 4870, loss = 0.97 (1904.4 examples/sec; 0.067 sec/batch)\n",
      "step 4880, loss = 0.80 (1890.5 examples/sec; 0.068 sec/batch)\n",
      "step 4890, loss = 0.89 (1974.2 examples/sec; 0.065 sec/batch)\n",
      "step 4900, loss = 0.92 (1921.7 examples/sec; 0.067 sec/batch)\n",
      "step 4910, loss = 0.82 (1987.3 examples/sec; 0.064 sec/batch)\n",
      "step 4920, loss = 0.83 (1859.4 examples/sec; 0.069 sec/batch)\n",
      "step 4930, loss = 0.93 (1857.2 examples/sec; 0.069 sec/batch)\n",
      "step 4940, loss = 1.07 (1900.2 examples/sec; 0.067 sec/batch)\n",
      "step 4950, loss = 0.99 (1842.5 examples/sec; 0.069 sec/batch)\n",
      "step 4960, loss = 0.78 (1880.8 examples/sec; 0.068 sec/batch)\n",
      "step 4970, loss = 1.03 (1893.6 examples/sec; 0.068 sec/batch)\n",
      "step 4980, loss = 0.89 (1813.5 examples/sec; 0.071 sec/batch)\n",
      "step 4990, loss = 0.94 (1823.5 examples/sec; 0.070 sec/batch)\n",
      "step 5000, loss = 0.89 (1849.8 examples/sec; 0.069 sec/batch)\n",
      "step 5010, loss = 1.05 (1839.4 examples/sec; 0.070 sec/batch)\n",
      "step 5020, loss = 0.83 (1829.7 examples/sec; 0.070 sec/batch)\n",
      "step 5030, loss = 0.81 (1891.2 examples/sec; 0.068 sec/batch)\n",
      "step 5040, loss = 0.81 (1897.1 examples/sec; 0.067 sec/batch)\n",
      "step 5050, loss = 0.79 (1794.1 examples/sec; 0.071 sec/batch)\n",
      "step 5060, loss = 0.83 (1875.0 examples/sec; 0.068 sec/batch)\n",
      "step 5070, loss = 0.86 (1824.9 examples/sec; 0.070 sec/batch)\n",
      "step 5080, loss = 0.98 (1731.8 examples/sec; 0.074 sec/batch)\n",
      "step 5090, loss = 0.78 (1814.1 examples/sec; 0.071 sec/batch)\n",
      "step 5100, loss = 0.75 (1847.3 examples/sec; 0.069 sec/batch)\n",
      "step 5110, loss = 1.00 (1885.7 examples/sec; 0.068 sec/batch)\n",
      "step 5120, loss = 1.01 (1909.1 examples/sec; 0.067 sec/batch)\n",
      "step 5130, loss = 0.87 (1814.5 examples/sec; 0.071 sec/batch)\n",
      "step 5140, loss = 0.98 (1877.6 examples/sec; 0.068 sec/batch)\n",
      "step 5150, loss = 0.92 (1827.9 examples/sec; 0.070 sec/batch)\n",
      "step 5160, loss = 0.88 (1895.3 examples/sec; 0.068 sec/batch)\n",
      "step 5170, loss = 0.86 (1848.5 examples/sec; 0.069 sec/batch)\n",
      "step 5180, loss = 0.99 (1751.1 examples/sec; 0.073 sec/batch)\n",
      "step 5190, loss = 0.79 (1898.3 examples/sec; 0.067 sec/batch)\n",
      "step 5200, loss = 1.01 (1754.8 examples/sec; 0.073 sec/batch)\n",
      "step 5210, loss = 0.97 (1755.1 examples/sec; 0.073 sec/batch)\n",
      "step 5220, loss = 0.95 (1765.2 examples/sec; 0.073 sec/batch)\n",
      "step 5230, loss = 0.90 (1828.2 examples/sec; 0.070 sec/batch)\n",
      "step 5240, loss = 0.95 (1830.6 examples/sec; 0.070 sec/batch)\n",
      "step 5250, loss = 0.92 (1904.1 examples/sec; 0.067 sec/batch)\n",
      "step 5260, loss = 1.09 (1825.5 examples/sec; 0.070 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5270, loss = 0.80 (1842.7 examples/sec; 0.069 sec/batch)\n",
      "step 5280, loss = 0.87 (1824.5 examples/sec; 0.070 sec/batch)\n",
      "step 5290, loss = 0.80 (1840.8 examples/sec; 0.070 sec/batch)\n",
      "step 5300, loss = 0.87 (1773.5 examples/sec; 0.072 sec/batch)\n",
      "step 5310, loss = 0.93 (1997.9 examples/sec; 0.064 sec/batch)\n",
      "step 5320, loss = 0.80 (1810.3 examples/sec; 0.071 sec/batch)\n",
      "step 5330, loss = 1.04 (1785.7 examples/sec; 0.072 sec/batch)\n",
      "step 5340, loss = 0.98 (1878.0 examples/sec; 0.068 sec/batch)\n",
      "step 5350, loss = 1.02 (1906.1 examples/sec; 0.067 sec/batch)\n",
      "step 5360, loss = 0.93 (1790.4 examples/sec; 0.071 sec/batch)\n",
      "step 5370, loss = 0.90 (1847.4 examples/sec; 0.069 sec/batch)\n",
      "step 5380, loss = 0.85 (1762.5 examples/sec; 0.073 sec/batch)\n",
      "step 5390, loss = 1.02 (1859.4 examples/sec; 0.069 sec/batch)\n",
      "step 5400, loss = 0.95 (1955.8 examples/sec; 0.065 sec/batch)\n",
      "step 5410, loss = 0.91 (1819.3 examples/sec; 0.070 sec/batch)\n",
      "step 5420, loss = 0.76 (1921.8 examples/sec; 0.067 sec/batch)\n",
      "step 5430, loss = 0.92 (1726.3 examples/sec; 0.074 sec/batch)\n",
      "step 5440, loss = 0.89 (1840.5 examples/sec; 0.070 sec/batch)\n",
      "step 5450, loss = 0.92 (1848.6 examples/sec; 0.069 sec/batch)\n",
      "step 5460, loss = 0.92 (1854.8 examples/sec; 0.069 sec/batch)\n",
      "step 5470, loss = 0.90 (1872.1 examples/sec; 0.068 sec/batch)\n",
      "step 5480, loss = 0.79 (1796.3 examples/sec; 0.071 sec/batch)\n",
      "step 5490, loss = 0.88 (1868.5 examples/sec; 0.069 sec/batch)\n",
      "step 5500, loss = 0.85 (1928.6 examples/sec; 0.066 sec/batch)\n",
      "step 5510, loss = 0.82 (1835.4 examples/sec; 0.070 sec/batch)\n",
      "step 5520, loss = 0.90 (1878.5 examples/sec; 0.068 sec/batch)\n",
      "step 5530, loss = 0.95 (1922.8 examples/sec; 0.067 sec/batch)\n",
      "step 5540, loss = 0.94 (1805.5 examples/sec; 0.071 sec/batch)\n",
      "step 5550, loss = 0.79 (1878.5 examples/sec; 0.068 sec/batch)\n",
      "step 5560, loss = 0.85 (1889.2 examples/sec; 0.068 sec/batch)\n",
      "step 5570, loss = 0.97 (1851.2 examples/sec; 0.069 sec/batch)\n",
      "step 5580, loss = 0.77 (1948.8 examples/sec; 0.066 sec/batch)\n",
      "step 5590, loss = 0.83 (1897.4 examples/sec; 0.067 sec/batch)\n",
      "step 5600, loss = 0.76 (1962.8 examples/sec; 0.065 sec/batch)\n",
      "step 5610, loss = 0.74 (1833.3 examples/sec; 0.070 sec/batch)\n",
      "step 5620, loss = 0.74 (1819.2 examples/sec; 0.070 sec/batch)\n",
      "step 5630, loss = 0.79 (1852.7 examples/sec; 0.069 sec/batch)\n",
      "step 5640, loss = 1.09 (2035.6 examples/sec; 0.063 sec/batch)\n",
      "step 5650, loss = 0.90 (1876.1 examples/sec; 0.068 sec/batch)\n",
      "step 5660, loss = 0.93 (1872.9 examples/sec; 0.068 sec/batch)\n",
      "step 5670, loss = 0.68 (1883.9 examples/sec; 0.068 sec/batch)\n",
      "step 5680, loss = 0.71 (1922.0 examples/sec; 0.067 sec/batch)\n",
      "step 5690, loss = 0.90 (1855.2 examples/sec; 0.069 sec/batch)\n",
      "step 5700, loss = 0.74 (1843.4 examples/sec; 0.069 sec/batch)\n",
      "step 5710, loss = 0.87 (1895.2 examples/sec; 0.068 sec/batch)\n",
      "step 5720, loss = 0.88 (1913.1 examples/sec; 0.067 sec/batch)\n",
      "step 5730, loss = 0.81 (1880.9 examples/sec; 0.068 sec/batch)\n",
      "step 5740, loss = 0.88 (1769.8 examples/sec; 0.072 sec/batch)\n",
      "step 5750, loss = 1.08 (1927.9 examples/sec; 0.066 sec/batch)\n",
      "step 5760, loss = 0.97 (1956.0 examples/sec; 0.065 sec/batch)\n",
      "step 5770, loss = 0.79 (1907.4 examples/sec; 0.067 sec/batch)\n",
      "step 5780, loss = 1.12 (1835.8 examples/sec; 0.070 sec/batch)\n",
      "step 5790, loss = 0.91 (1931.0 examples/sec; 0.066 sec/batch)\n",
      "step 5800, loss = 0.98 (1833.8 examples/sec; 0.070 sec/batch)\n",
      "step 5810, loss = 0.82 (1910.2 examples/sec; 0.067 sec/batch)\n",
      "step 5820, loss = 0.87 (1848.6 examples/sec; 0.069 sec/batch)\n",
      "step 5830, loss = 0.85 (1921.5 examples/sec; 0.067 sec/batch)\n",
      "step 5840, loss = 0.72 (1885.7 examples/sec; 0.068 sec/batch)\n",
      "step 5850, loss = 0.91 (1863.6 examples/sec; 0.069 sec/batch)\n",
      "step 5860, loss = 0.82 (1852.5 examples/sec; 0.069 sec/batch)\n",
      "step 5870, loss = 0.80 (1869.5 examples/sec; 0.068 sec/batch)\n",
      "step 5880, loss = 1.14 (1831.9 examples/sec; 0.070 sec/batch)\n",
      "step 5890, loss = 1.02 (1822.7 examples/sec; 0.070 sec/batch)\n",
      "step 5900, loss = 1.08 (1941.5 examples/sec; 0.066 sec/batch)\n",
      "step 5910, loss = 0.97 (1722.9 examples/sec; 0.074 sec/batch)\n",
      "step 5920, loss = 0.90 (1893.8 examples/sec; 0.068 sec/batch)\n",
      "step 5930, loss = 0.73 (2004.4 examples/sec; 0.064 sec/batch)\n",
      "step 5940, loss = 0.82 (1802.7 examples/sec; 0.071 sec/batch)\n",
      "step 5950, loss = 0.78 (1914.6 examples/sec; 0.067 sec/batch)\n",
      "step 5960, loss = 0.87 (1806.8 examples/sec; 0.071 sec/batch)\n",
      "step 5970, loss = 0.89 (1909.4 examples/sec; 0.067 sec/batch)\n",
      "step 5980, loss = 0.82 (1929.9 examples/sec; 0.066 sec/batch)\n",
      "step 5990, loss = 0.89 (1871.5 examples/sec; 0.068 sec/batch)\n",
      "step 6000, loss = 0.94 (1890.1 examples/sec; 0.068 sec/batch)\n",
      "step 6010, loss = 0.74 (1866.8 examples/sec; 0.069 sec/batch)\n",
      "step 6020, loss = 0.91 (1914.2 examples/sec; 0.067 sec/batch)\n",
      "step 6030, loss = 0.95 (1891.5 examples/sec; 0.068 sec/batch)\n",
      "step 6040, loss = 0.88 (1828.9 examples/sec; 0.070 sec/batch)\n",
      "step 6050, loss = 0.96 (1915.0 examples/sec; 0.067 sec/batch)\n",
      "step 6060, loss = 0.89 (1905.9 examples/sec; 0.067 sec/batch)\n",
      "step 6070, loss = 0.71 (1766.3 examples/sec; 0.072 sec/batch)\n",
      "step 6080, loss = 0.80 (1793.3 examples/sec; 0.071 sec/batch)\n",
      "step 6090, loss = 0.81 (1859.0 examples/sec; 0.069 sec/batch)\n",
      "step 6100, loss = 0.85 (1910.7 examples/sec; 0.067 sec/batch)\n",
      "step 6110, loss = 0.93 (1836.0 examples/sec; 0.070 sec/batch)\n",
      "step 6120, loss = 0.95 (1858.3 examples/sec; 0.069 sec/batch)\n",
      "step 6130, loss = 1.09 (1960.2 examples/sec; 0.065 sec/batch)\n",
      "step 6140, loss = 0.94 (1908.4 examples/sec; 0.067 sec/batch)\n",
      "step 6150, loss = 0.82 (1827.6 examples/sec; 0.070 sec/batch)\n",
      "step 6160, loss = 0.85 (1832.0 examples/sec; 0.070 sec/batch)\n",
      "step 6170, loss = 0.88 (1893.3 examples/sec; 0.068 sec/batch)\n",
      "step 6180, loss = 0.71 (1867.0 examples/sec; 0.069 sec/batch)\n",
      "step 6190, loss = 0.65 (1802.9 examples/sec; 0.071 sec/batch)\n",
      "step 6200, loss = 0.87 (1839.3 examples/sec; 0.070 sec/batch)\n",
      "step 6210, loss = 0.92 (1907.9 examples/sec; 0.067 sec/batch)\n",
      "step 6220, loss = 0.71 (1891.7 examples/sec; 0.068 sec/batch)\n",
      "step 6230, loss = 0.96 (1934.0 examples/sec; 0.066 sec/batch)\n",
      "step 6240, loss = 0.93 (1853.1 examples/sec; 0.069 sec/batch)\n",
      "step 6250, loss = 0.97 (1799.6 examples/sec; 0.071 sec/batch)\n",
      "step 6260, loss = 0.87 (1788.2 examples/sec; 0.072 sec/batch)\n",
      "step 6270, loss = 0.77 (1864.6 examples/sec; 0.069 sec/batch)\n",
      "step 6280, loss = 0.75 (1846.9 examples/sec; 0.069 sec/batch)\n",
      "step 6290, loss = 0.96 (1880.4 examples/sec; 0.068 sec/batch)\n",
      "step 6300, loss = 0.86 (1883.3 examples/sec; 0.068 sec/batch)\n",
      "step 6310, loss = 0.81 (1879.1 examples/sec; 0.068 sec/batch)\n",
      "step 6320, loss = 0.98 (1874.5 examples/sec; 0.068 sec/batch)\n",
      "step 6330, loss = 0.84 (1840.4 examples/sec; 0.070 sec/batch)\n",
      "step 6340, loss = 0.82 (2097.5 examples/sec; 0.061 sec/batch)\n",
      "step 6350, loss = 0.80 (1813.1 examples/sec; 0.071 sec/batch)\n",
      "step 6360, loss = 0.93 (1855.7 examples/sec; 0.069 sec/batch)\n",
      "step 6370, loss = 0.76 (1976.2 examples/sec; 0.065 sec/batch)\n",
      "step 6380, loss = 0.73 (1869.2 examples/sec; 0.068 sec/batch)\n",
      "step 6390, loss = 1.00 (1858.4 examples/sec; 0.069 sec/batch)\n",
      "step 6400, loss = 0.83 (1807.6 examples/sec; 0.071 sec/batch)\n",
      "step 6410, loss = 0.86 (1904.8 examples/sec; 0.067 sec/batch)\n",
      "step 6420, loss = 0.86 (1876.3 examples/sec; 0.068 sec/batch)\n",
      "step 6430, loss = 0.85 (1864.2 examples/sec; 0.069 sec/batch)\n",
      "step 6440, loss = 0.83 (1913.3 examples/sec; 0.067 sec/batch)\n",
      "step 6450, loss = 0.97 (1977.5 examples/sec; 0.065 sec/batch)\n",
      "step 6460, loss = 0.78 (1804.2 examples/sec; 0.071 sec/batch)\n",
      "step 6470, loss = 0.98 (1897.3 examples/sec; 0.067 sec/batch)\n",
      "step 6480, loss = 0.79 (1920.7 examples/sec; 0.067 sec/batch)\n",
      "step 6490, loss = 0.78 (1940.7 examples/sec; 0.066 sec/batch)\n",
      "step 6500, loss = 0.84 (1778.2 examples/sec; 0.072 sec/batch)\n",
      "step 6510, loss = 0.94 (1824.5 examples/sec; 0.070 sec/batch)\n",
      "step 6520, loss = 0.81 (1826.6 examples/sec; 0.070 sec/batch)\n",
      "step 6530, loss = 0.84 (1876.1 examples/sec; 0.068 sec/batch)\n",
      "step 6540, loss = 0.70 (1930.8 examples/sec; 0.066 sec/batch)\n",
      "step 6550, loss = 0.79 (2033.1 examples/sec; 0.063 sec/batch)\n",
      "step 6560, loss = 0.86 (1937.4 examples/sec; 0.066 sec/batch)\n",
      "step 6570, loss = 0.73 (1829.5 examples/sec; 0.070 sec/batch)\n",
      "step 6580, loss = 1.17 (1942.1 examples/sec; 0.066 sec/batch)\n",
      "step 6590, loss = 0.83 (1867.0 examples/sec; 0.069 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6600, loss = 0.72 (1864.4 examples/sec; 0.069 sec/batch)\n",
      "step 6610, loss = 0.86 (1785.7 examples/sec; 0.072 sec/batch)\n",
      "step 6620, loss = 0.80 (1832.1 examples/sec; 0.070 sec/batch)\n",
      "step 6630, loss = 0.77 (1885.9 examples/sec; 0.068 sec/batch)\n",
      "step 6640, loss = 0.75 (1871.4 examples/sec; 0.068 sec/batch)\n",
      "step 6650, loss = 0.83 (1868.1 examples/sec; 0.069 sec/batch)\n",
      "step 6660, loss = 0.72 (1868.4 examples/sec; 0.069 sec/batch)\n",
      "step 6670, loss = 0.87 (1778.8 examples/sec; 0.072 sec/batch)\n",
      "step 6680, loss = 0.83 (1829.5 examples/sec; 0.070 sec/batch)\n",
      "step 6690, loss = 0.80 (1740.4 examples/sec; 0.074 sec/batch)\n",
      "step 6700, loss = 0.68 (1828.9 examples/sec; 0.070 sec/batch)\n",
      "step 6710, loss = 0.87 (1801.8 examples/sec; 0.071 sec/batch)\n",
      "step 6720, loss = 0.88 (1891.4 examples/sec; 0.068 sec/batch)\n",
      "step 6730, loss = 0.87 (1872.7 examples/sec; 0.068 sec/batch)\n",
      "step 6740, loss = 0.88 (1855.7 examples/sec; 0.069 sec/batch)\n",
      "step 6750, loss = 0.70 (1826.5 examples/sec; 0.070 sec/batch)\n",
      "step 6760, loss = 0.81 (1865.4 examples/sec; 0.069 sec/batch)\n",
      "step 6770, loss = 0.83 (1875.1 examples/sec; 0.068 sec/batch)\n",
      "step 6780, loss = 0.94 (1911.9 examples/sec; 0.067 sec/batch)\n",
      "step 6790, loss = 0.79 (1837.9 examples/sec; 0.070 sec/batch)\n",
      "step 6800, loss = 0.79 (1766.4 examples/sec; 0.072 sec/batch)\n",
      "step 6810, loss = 0.78 (1804.2 examples/sec; 0.071 sec/batch)\n",
      "step 6820, loss = 0.85 (1857.5 examples/sec; 0.069 sec/batch)\n",
      "step 6830, loss = 0.91 (1873.0 examples/sec; 0.068 sec/batch)\n",
      "step 6840, loss = 0.91 (1792.9 examples/sec; 0.071 sec/batch)\n",
      "step 6850, loss = 0.84 (1943.0 examples/sec; 0.066 sec/batch)\n",
      "step 6860, loss = 0.85 (1896.1 examples/sec; 0.068 sec/batch)\n",
      "step 6870, loss = 0.77 (1767.6 examples/sec; 0.072 sec/batch)\n",
      "step 6880, loss = 0.90 (1828.7 examples/sec; 0.070 sec/batch)\n",
      "step 6890, loss = 0.85 (1787.5 examples/sec; 0.072 sec/batch)\n",
      "step 6900, loss = 0.85 (1860.5 examples/sec; 0.069 sec/batch)\n",
      "step 6910, loss = 0.98 (1926.4 examples/sec; 0.066 sec/batch)\n",
      "step 6920, loss = 0.82 (1847.6 examples/sec; 0.069 sec/batch)\n",
      "step 6930, loss = 0.87 (1931.6 examples/sec; 0.066 sec/batch)\n",
      "step 6940, loss = 0.81 (1875.2 examples/sec; 0.068 sec/batch)\n",
      "step 6950, loss = 1.02 (1827.0 examples/sec; 0.070 sec/batch)\n",
      "step 6960, loss = 0.77 (1826.0 examples/sec; 0.070 sec/batch)\n",
      "step 6970, loss = 0.84 (1897.0 examples/sec; 0.067 sec/batch)\n",
      "step 6980, loss = 0.87 (1805.0 examples/sec; 0.071 sec/batch)\n",
      "step 6990, loss = 0.79 (1813.2 examples/sec; 0.071 sec/batch)\n",
      "step 7000, loss = 0.79 (1867.0 examples/sec; 0.069 sec/batch)\n",
      "step 7010, loss = 0.89 (1889.0 examples/sec; 0.068 sec/batch)\n",
      "step 7020, loss = 0.83 (1783.1 examples/sec; 0.072 sec/batch)\n",
      "step 7030, loss = 0.82 (1845.6 examples/sec; 0.069 sec/batch)\n",
      "step 7040, loss = 0.80 (1975.1 examples/sec; 0.065 sec/batch)\n",
      "step 7050, loss = 0.90 (1909.9 examples/sec; 0.067 sec/batch)\n",
      "step 7060, loss = 0.90 (1806.7 examples/sec; 0.071 sec/batch)\n",
      "step 7070, loss = 0.77 (1902.5 examples/sec; 0.067 sec/batch)\n",
      "step 7080, loss = 0.81 (1808.7 examples/sec; 0.071 sec/batch)\n",
      "step 7090, loss = 0.91 (1732.5 examples/sec; 0.074 sec/batch)\n",
      "step 7100, loss = 0.92 (1895.2 examples/sec; 0.068 sec/batch)\n",
      "step 7110, loss = 0.73 (1903.2 examples/sec; 0.067 sec/batch)\n",
      "step 7120, loss = 0.88 (1865.6 examples/sec; 0.069 sec/batch)\n",
      "step 7130, loss = 0.66 (1817.5 examples/sec; 0.070 sec/batch)\n",
      "step 7140, loss = 0.94 (1850.9 examples/sec; 0.069 sec/batch)\n",
      "step 7150, loss = 0.76 (1864.2 examples/sec; 0.069 sec/batch)\n",
      "step 7160, loss = 0.80 (1792.9 examples/sec; 0.071 sec/batch)\n",
      "step 7170, loss = 0.84 (1827.9 examples/sec; 0.070 sec/batch)\n",
      "step 7180, loss = 0.83 (1923.8 examples/sec; 0.067 sec/batch)\n",
      "step 7190, loss = 0.75 (1763.5 examples/sec; 0.073 sec/batch)\n",
      "step 7200, loss = 0.84 (1979.9 examples/sec; 0.065 sec/batch)\n",
      "step 7210, loss = 0.78 (1818.0 examples/sec; 0.070 sec/batch)\n",
      "step 7220, loss = 0.83 (1824.5 examples/sec; 0.070 sec/batch)\n",
      "step 7230, loss = 1.00 (1815.8 examples/sec; 0.070 sec/batch)\n",
      "step 7240, loss = 0.94 (1760.6 examples/sec; 0.073 sec/batch)\n",
      "step 7250, loss = 0.79 (1831.5 examples/sec; 0.070 sec/batch)\n",
      "step 7260, loss = 0.83 (1888.1 examples/sec; 0.068 sec/batch)\n",
      "step 7270, loss = 0.79 (1860.9 examples/sec; 0.069 sec/batch)\n",
      "step 7280, loss = 0.80 (1795.7 examples/sec; 0.071 sec/batch)\n",
      "step 7290, loss = 0.86 (1781.6 examples/sec; 0.072 sec/batch)\n",
      "step 7300, loss = 0.93 (1932.9 examples/sec; 0.066 sec/batch)\n",
      "step 7310, loss = 0.76 (1778.6 examples/sec; 0.072 sec/batch)\n",
      "step 7320, loss = 0.93 (1759.5 examples/sec; 0.073 sec/batch)\n",
      "step 7330, loss = 0.74 (1921.6 examples/sec; 0.067 sec/batch)\n",
      "step 7340, loss = 0.86 (1892.4 examples/sec; 0.068 sec/batch)\n",
      "step 7350, loss = 0.72 (1864.4 examples/sec; 0.069 sec/batch)\n",
      "step 7360, loss = 0.85 (1799.7 examples/sec; 0.071 sec/batch)\n",
      "step 7370, loss = 0.67 (1795.3 examples/sec; 0.071 sec/batch)\n",
      "step 7380, loss = 0.72 (1856.3 examples/sec; 0.069 sec/batch)\n",
      "step 7390, loss = 0.72 (1799.0 examples/sec; 0.071 sec/batch)\n",
      "step 7400, loss = 0.98 (1835.6 examples/sec; 0.070 sec/batch)\n",
      "step 7410, loss = 0.79 (1745.3 examples/sec; 0.073 sec/batch)\n",
      "step 7420, loss = 0.86 (1875.7 examples/sec; 0.068 sec/batch)\n",
      "step 7430, loss = 0.81 (1822.4 examples/sec; 0.070 sec/batch)\n",
      "step 7440, loss = 0.87 (1876.4 examples/sec; 0.068 sec/batch)\n",
      "step 7450, loss = 0.74 (1893.9 examples/sec; 0.068 sec/batch)\n",
      "step 7460, loss = 0.95 (1831.0 examples/sec; 0.070 sec/batch)\n",
      "step 7470, loss = 0.75 (1887.4 examples/sec; 0.068 sec/batch)\n",
      "step 7480, loss = 0.94 (1812.2 examples/sec; 0.071 sec/batch)\n",
      "step 7490, loss = 0.80 (1911.9 examples/sec; 0.067 sec/batch)\n",
      "step 7500, loss = 0.78 (1909.0 examples/sec; 0.067 sec/batch)\n",
      "step 7510, loss = 0.90 (1786.9 examples/sec; 0.072 sec/batch)\n",
      "step 7520, loss = 0.88 (1909.8 examples/sec; 0.067 sec/batch)\n",
      "step 7530, loss = 0.82 (1807.6 examples/sec; 0.071 sec/batch)\n",
      "step 7540, loss = 0.80 (1827.9 examples/sec; 0.070 sec/batch)\n",
      "step 7550, loss = 0.92 (1803.7 examples/sec; 0.071 sec/batch)\n",
      "step 7560, loss = 0.75 (1854.2 examples/sec; 0.069 sec/batch)\n",
      "step 7570, loss = 0.82 (1902.0 examples/sec; 0.067 sec/batch)\n",
      "step 7580, loss = 0.83 (1884.1 examples/sec; 0.068 sec/batch)\n",
      "step 7590, loss = 0.84 (1908.5 examples/sec; 0.067 sec/batch)\n",
      "step 7600, loss = 0.83 (1876.3 examples/sec; 0.068 sec/batch)\n",
      "step 7610, loss = 0.83 (1882.6 examples/sec; 0.068 sec/batch)\n",
      "step 7620, loss = 0.82 (1924.7 examples/sec; 0.067 sec/batch)\n",
      "step 7630, loss = 0.80 (1886.9 examples/sec; 0.068 sec/batch)\n",
      "step 7640, loss = 0.75 (1808.0 examples/sec; 0.071 sec/batch)\n",
      "step 7650, loss = 0.72 (1789.2 examples/sec; 0.072 sec/batch)\n",
      "step 7660, loss = 0.91 (1873.2 examples/sec; 0.068 sec/batch)\n",
      "step 7670, loss = 0.74 (1822.9 examples/sec; 0.070 sec/batch)\n",
      "step 7680, loss = 0.83 (1859.9 examples/sec; 0.069 sec/batch)\n",
      "step 7690, loss = 0.77 (1803.8 examples/sec; 0.071 sec/batch)\n",
      "step 7700, loss = 0.81 (1857.0 examples/sec; 0.069 sec/batch)\n",
      "step 7710, loss = 0.88 (1855.9 examples/sec; 0.069 sec/batch)\n",
      "step 7720, loss = 1.07 (1818.8 examples/sec; 0.070 sec/batch)\n",
      "step 7730, loss = 0.78 (1853.3 examples/sec; 0.069 sec/batch)\n",
      "step 7740, loss = 0.93 (1859.3 examples/sec; 0.069 sec/batch)\n",
      "step 7750, loss = 0.71 (1815.4 examples/sec; 0.071 sec/batch)\n",
      "step 7760, loss = 0.80 (2045.5 examples/sec; 0.063 sec/batch)\n",
      "step 7770, loss = 0.74 (1845.5 examples/sec; 0.069 sec/batch)\n",
      "step 7780, loss = 0.76 (2028.6 examples/sec; 0.063 sec/batch)\n",
      "step 7790, loss = 0.74 (1902.5 examples/sec; 0.067 sec/batch)\n",
      "step 7800, loss = 0.89 (1822.8 examples/sec; 0.070 sec/batch)\n",
      "step 7810, loss = 0.84 (1885.8 examples/sec; 0.068 sec/batch)\n",
      "step 7820, loss = 0.65 (1820.7 examples/sec; 0.070 sec/batch)\n",
      "step 7830, loss = 0.88 (1795.7 examples/sec; 0.071 sec/batch)\n",
      "step 7840, loss = 0.86 (1935.1 examples/sec; 0.066 sec/batch)\n",
      "step 7850, loss = 0.76 (1889.9 examples/sec; 0.068 sec/batch)\n",
      "step 7860, loss = 0.77 (1783.5 examples/sec; 0.072 sec/batch)\n",
      "step 7870, loss = 0.66 (1848.6 examples/sec; 0.069 sec/batch)\n",
      "step 7880, loss = 0.79 (1899.7 examples/sec; 0.067 sec/batch)\n",
      "step 7890, loss = 0.87 (1848.9 examples/sec; 0.069 sec/batch)\n",
      "step 7900, loss = 0.82 (1823.5 examples/sec; 0.070 sec/batch)\n",
      "step 7910, loss = 0.74 (1838.8 examples/sec; 0.070 sec/batch)\n",
      "step 7920, loss = 0.80 (1855.8 examples/sec; 0.069 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7930, loss = 0.83 (1809.2 examples/sec; 0.071 sec/batch)\n",
      "step 7940, loss = 0.76 (1820.6 examples/sec; 0.070 sec/batch)\n",
      "step 7950, loss = 0.74 (1910.7 examples/sec; 0.067 sec/batch)\n",
      "step 7960, loss = 0.81 (1828.5 examples/sec; 0.070 sec/batch)\n",
      "step 7970, loss = 0.83 (1785.9 examples/sec; 0.072 sec/batch)\n",
      "step 7980, loss = 0.67 (1822.5 examples/sec; 0.070 sec/batch)\n",
      "step 7990, loss = 0.72 (1848.1 examples/sec; 0.069 sec/batch)\n",
      "step 8000, loss = 0.75 (1864.9 examples/sec; 0.069 sec/batch)\n",
      "step 8010, loss = 0.71 (1750.8 examples/sec; 0.073 sec/batch)\n",
      "step 8020, loss = 0.94 (1845.1 examples/sec; 0.069 sec/batch)\n",
      "step 8030, loss = 0.85 (1846.8 examples/sec; 0.069 sec/batch)\n",
      "step 8040, loss = 0.70 (1954.9 examples/sec; 0.065 sec/batch)\n",
      "step 8050, loss = 0.64 (1849.2 examples/sec; 0.069 sec/batch)\n",
      "step 8060, loss = 0.63 (1820.3 examples/sec; 0.070 sec/batch)\n",
      "step 8070, loss = 0.87 (1853.4 examples/sec; 0.069 sec/batch)\n",
      "step 8080, loss = 0.74 (1935.0 examples/sec; 0.066 sec/batch)\n",
      "step 8090, loss = 0.95 (1815.4 examples/sec; 0.071 sec/batch)\n",
      "step 8100, loss = 0.71 (1870.9 examples/sec; 0.068 sec/batch)\n",
      "step 8110, loss = 0.77 (1880.0 examples/sec; 0.068 sec/batch)\n",
      "step 8120, loss = 0.68 (1973.0 examples/sec; 0.065 sec/batch)\n",
      "step 8130, loss = 0.89 (1909.1 examples/sec; 0.067 sec/batch)\n",
      "step 8140, loss = 0.90 (1803.9 examples/sec; 0.071 sec/batch)\n",
      "step 8150, loss = 0.97 (1745.1 examples/sec; 0.073 sec/batch)\n",
      "step 8160, loss = 0.71 (1795.8 examples/sec; 0.071 sec/batch)\n",
      "step 8170, loss = 0.88 (1915.3 examples/sec; 0.067 sec/batch)\n",
      "step 8180, loss = 0.77 (1897.7 examples/sec; 0.067 sec/batch)\n",
      "step 8190, loss = 0.79 (1804.0 examples/sec; 0.071 sec/batch)\n",
      "step 8200, loss = 0.90 (1802.0 examples/sec; 0.071 sec/batch)\n",
      "step 8210, loss = 0.68 (1787.3 examples/sec; 0.072 sec/batch)\n",
      "step 8220, loss = 0.80 (1859.6 examples/sec; 0.069 sec/batch)\n",
      "step 8230, loss = 0.79 (1926.7 examples/sec; 0.066 sec/batch)\n",
      "step 8240, loss = 0.76 (1862.2 examples/sec; 0.069 sec/batch)\n",
      "step 8250, loss = 0.80 (1805.8 examples/sec; 0.071 sec/batch)\n",
      "step 8260, loss = 0.88 (1844.8 examples/sec; 0.069 sec/batch)\n",
      "step 8270, loss = 0.70 (1824.6 examples/sec; 0.070 sec/batch)\n",
      "step 8280, loss = 0.94 (2006.9 examples/sec; 0.064 sec/batch)\n",
      "step 8290, loss = 0.86 (1770.4 examples/sec; 0.072 sec/batch)\n",
      "step 8300, loss = 0.80 (1936.6 examples/sec; 0.066 sec/batch)\n",
      "step 8310, loss = 0.92 (1896.0 examples/sec; 0.068 sec/batch)\n",
      "step 8320, loss = 0.66 (1846.1 examples/sec; 0.069 sec/batch)\n",
      "step 8330, loss = 0.80 (1765.0 examples/sec; 0.073 sec/batch)\n",
      "step 8340, loss = 0.77 (1827.4 examples/sec; 0.070 sec/batch)\n",
      "step 8350, loss = 0.84 (1884.2 examples/sec; 0.068 sec/batch)\n",
      "step 8360, loss = 0.78 (1922.2 examples/sec; 0.067 sec/batch)\n",
      "step 8370, loss = 0.89 (2065.6 examples/sec; 0.062 sec/batch)\n",
      "step 8380, loss = 0.71 (1777.1 examples/sec; 0.072 sec/batch)\n",
      "step 8390, loss = 0.91 (1812.6 examples/sec; 0.071 sec/batch)\n",
      "step 8400, loss = 0.65 (1842.7 examples/sec; 0.069 sec/batch)\n",
      "step 8410, loss = 0.80 (1823.2 examples/sec; 0.070 sec/batch)\n",
      "step 8420, loss = 0.81 (1883.3 examples/sec; 0.068 sec/batch)\n",
      "step 8430, loss = 0.83 (1917.1 examples/sec; 0.067 sec/batch)\n",
      "step 8440, loss = 0.80 (1873.9 examples/sec; 0.068 sec/batch)\n",
      "step 8450, loss = 0.76 (1872.6 examples/sec; 0.068 sec/batch)\n",
      "step 8460, loss = 0.92 (1893.5 examples/sec; 0.068 sec/batch)\n",
      "step 8470, loss = 0.81 (1871.2 examples/sec; 0.068 sec/batch)\n",
      "step 8480, loss = 0.67 (1870.3 examples/sec; 0.068 sec/batch)\n",
      "step 8490, loss = 0.70 (1905.0 examples/sec; 0.067 sec/batch)\n",
      "step 8500, loss = 0.66 (1884.4 examples/sec; 0.068 sec/batch)\n",
      "step 8510, loss = 0.68 (1804.5 examples/sec; 0.071 sec/batch)\n",
      "step 8520, loss = 0.77 (1908.2 examples/sec; 0.067 sec/batch)\n",
      "step 8530, loss = 0.77 (1888.0 examples/sec; 0.068 sec/batch)\n",
      "step 8540, loss = 0.84 (1912.4 examples/sec; 0.067 sec/batch)\n",
      "step 8550, loss = 0.82 (1934.2 examples/sec; 0.066 sec/batch)\n",
      "step 8560, loss = 0.90 (2027.9 examples/sec; 0.063 sec/batch)\n",
      "step 8570, loss = 0.63 (1877.2 examples/sec; 0.068 sec/batch)\n",
      "step 8580, loss = 0.75 (1796.5 examples/sec; 0.071 sec/batch)\n",
      "step 8590, loss = 0.67 (1840.9 examples/sec; 0.070 sec/batch)\n",
      "step 8600, loss = 0.87 (1921.2 examples/sec; 0.067 sec/batch)\n",
      "step 8610, loss = 0.74 (1775.1 examples/sec; 0.072 sec/batch)\n",
      "step 8620, loss = 0.74 (1888.3 examples/sec; 0.068 sec/batch)\n",
      "step 8630, loss = 0.84 (1852.9 examples/sec; 0.069 sec/batch)\n",
      "step 8640, loss = 0.67 (1823.2 examples/sec; 0.070 sec/batch)\n",
      "step 8650, loss = 0.67 (1843.6 examples/sec; 0.069 sec/batch)\n",
      "step 8660, loss = 0.95 (1859.9 examples/sec; 0.069 sec/batch)\n",
      "step 8670, loss = 0.77 (1737.8 examples/sec; 0.074 sec/batch)\n",
      "step 8680, loss = 0.77 (1833.9 examples/sec; 0.070 sec/batch)\n",
      "step 8690, loss = 0.69 (1823.5 examples/sec; 0.070 sec/batch)\n",
      "step 8700, loss = 0.89 (1873.1 examples/sec; 0.068 sec/batch)\n",
      "step 8710, loss = 0.72 (1852.9 examples/sec; 0.069 sec/batch)\n",
      "step 8720, loss = 0.74 (1922.6 examples/sec; 0.067 sec/batch)\n",
      "step 8730, loss = 0.82 (1796.9 examples/sec; 0.071 sec/batch)\n",
      "step 8740, loss = 0.78 (1820.8 examples/sec; 0.070 sec/batch)\n",
      "step 8750, loss = 0.76 (2083.3 examples/sec; 0.061 sec/batch)\n",
      "step 8760, loss = 0.70 (1812.1 examples/sec; 0.071 sec/batch)\n",
      "step 8770, loss = 0.69 (1930.5 examples/sec; 0.066 sec/batch)\n",
      "step 8780, loss = 0.85 (1964.0 examples/sec; 0.065 sec/batch)\n",
      "step 8790, loss = 0.76 (1865.5 examples/sec; 0.069 sec/batch)\n",
      "step 8800, loss = 0.80 (1841.0 examples/sec; 0.070 sec/batch)\n",
      "step 8810, loss = 0.74 (1879.9 examples/sec; 0.068 sec/batch)\n",
      "step 8820, loss = 0.80 (1846.9 examples/sec; 0.069 sec/batch)\n",
      "step 8830, loss = 0.88 (1931.1 examples/sec; 0.066 sec/batch)\n",
      "step 8840, loss = 0.98 (1932.0 examples/sec; 0.066 sec/batch)\n",
      "step 8850, loss = 0.71 (1843.2 examples/sec; 0.069 sec/batch)\n",
      "step 8860, loss = 1.00 (1904.0 examples/sec; 0.067 sec/batch)\n",
      "step 8870, loss = 0.72 (1882.1 examples/sec; 0.068 sec/batch)\n",
      "step 8880, loss = 0.66 (1858.3 examples/sec; 0.069 sec/batch)\n",
      "step 8890, loss = 0.76 (1937.9 examples/sec; 0.066 sec/batch)\n",
      "step 8900, loss = 0.79 (1778.7 examples/sec; 0.072 sec/batch)\n",
      "step 8910, loss = 0.81 (1820.0 examples/sec; 0.070 sec/batch)\n",
      "step 8920, loss = 0.84 (1774.6 examples/sec; 0.072 sec/batch)\n",
      "step 8930, loss = 0.70 (1850.8 examples/sec; 0.069 sec/batch)\n",
      "step 8940, loss = 0.80 (1852.4 examples/sec; 0.069 sec/batch)\n",
      "step 8950, loss = 0.79 (1860.0 examples/sec; 0.069 sec/batch)\n",
      "step 8960, loss = 0.84 (1866.5 examples/sec; 0.069 sec/batch)\n",
      "step 8970, loss = 0.80 (1881.3 examples/sec; 0.068 sec/batch)\n",
      "step 8980, loss = 0.92 (1825.9 examples/sec; 0.070 sec/batch)\n",
      "step 8990, loss = 0.82 (1885.3 examples/sec; 0.068 sec/batch)\n",
      "step 9000, loss = 0.73 (1854.1 examples/sec; 0.069 sec/batch)\n",
      "step 9010, loss = 0.65 (1829.3 examples/sec; 0.070 sec/batch)\n",
      "step 9020, loss = 0.74 (1868.3 examples/sec; 0.069 sec/batch)\n",
      "step 9030, loss = 0.67 (1881.1 examples/sec; 0.068 sec/batch)\n",
      "step 9040, loss = 0.75 (1787.0 examples/sec; 0.072 sec/batch)\n",
      "step 9050, loss = 0.73 (1855.6 examples/sec; 0.069 sec/batch)\n",
      "step 9060, loss = 0.68 (1851.6 examples/sec; 0.069 sec/batch)\n",
      "step 9070, loss = 0.66 (1894.9 examples/sec; 0.068 sec/batch)\n",
      "step 9080, loss = 0.73 (1941.9 examples/sec; 0.066 sec/batch)\n",
      "step 9090, loss = 0.77 (1804.2 examples/sec; 0.071 sec/batch)\n",
      "step 9100, loss = 0.86 (1901.2 examples/sec; 0.067 sec/batch)\n",
      "step 9110, loss = 0.83 (1844.5 examples/sec; 0.069 sec/batch)\n",
      "step 9120, loss = 0.71 (1840.9 examples/sec; 0.070 sec/batch)\n",
      "step 9130, loss = 0.87 (1889.7 examples/sec; 0.068 sec/batch)\n",
      "step 9140, loss = 0.75 (1847.3 examples/sec; 0.069 sec/batch)\n",
      "step 9150, loss = 0.85 (1718.7 examples/sec; 0.074 sec/batch)\n",
      "step 9160, loss = 0.69 (1878.1 examples/sec; 0.068 sec/batch)\n",
      "step 9170, loss = 0.68 (1810.8 examples/sec; 0.071 sec/batch)\n",
      "step 9180, loss = 0.66 (1875.7 examples/sec; 0.068 sec/batch)\n",
      "step 9190, loss = 0.66 (1847.4 examples/sec; 0.069 sec/batch)\n",
      "step 9200, loss = 0.90 (1925.6 examples/sec; 0.066 sec/batch)\n",
      "step 9210, loss = 0.59 (1839.1 examples/sec; 0.070 sec/batch)\n",
      "step 9220, loss = 0.66 (1883.0 examples/sec; 0.068 sec/batch)\n",
      "step 9230, loss = 0.73 (1867.7 examples/sec; 0.069 sec/batch)\n",
      "step 9240, loss = 0.74 (1910.0 examples/sec; 0.067 sec/batch)\n",
      "step 9250, loss = 0.77 (1815.1 examples/sec; 0.071 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 9260, loss = 0.83 (1862.7 examples/sec; 0.069 sec/batch)\n",
      "step 9270, loss = 0.80 (1809.0 examples/sec; 0.071 sec/batch)\n",
      "step 9280, loss = 0.71 (1787.0 examples/sec; 0.072 sec/batch)\n",
      "step 9290, loss = 0.85 (1825.6 examples/sec; 0.070 sec/batch)\n",
      "step 9300, loss = 0.81 (1958.8 examples/sec; 0.065 sec/batch)\n",
      "step 9310, loss = 0.72 (1773.5 examples/sec; 0.072 sec/batch)\n",
      "step 9320, loss = 0.96 (1716.6 examples/sec; 0.075 sec/batch)\n",
      "step 9330, loss = 0.92 (1828.0 examples/sec; 0.070 sec/batch)\n",
      "step 9340, loss = 0.79 (1884.0 examples/sec; 0.068 sec/batch)\n",
      "step 9350, loss = 0.65 (1808.4 examples/sec; 0.071 sec/batch)\n",
      "step 9360, loss = 0.80 (1842.8 examples/sec; 0.069 sec/batch)\n",
      "step 9370, loss = 0.73 (1857.5 examples/sec; 0.069 sec/batch)\n",
      "step 9380, loss = 0.72 (1849.8 examples/sec; 0.069 sec/batch)\n",
      "step 9390, loss = 0.86 (1902.0 examples/sec; 0.067 sec/batch)\n",
      "step 9400, loss = 0.72 (1904.7 examples/sec; 0.067 sec/batch)\n",
      "step 9410, loss = 0.79 (1844.8 examples/sec; 0.069 sec/batch)\n",
      "step 9420, loss = 0.70 (1938.0 examples/sec; 0.066 sec/batch)\n",
      "step 9430, loss = 0.64 (1893.0 examples/sec; 0.068 sec/batch)\n",
      "step 9440, loss = 0.70 (1859.2 examples/sec; 0.069 sec/batch)\n",
      "step 9450, loss = 0.83 (1836.2 examples/sec; 0.070 sec/batch)\n",
      "step 9460, loss = 0.64 (1875.1 examples/sec; 0.068 sec/batch)\n",
      "step 9470, loss = 0.83 (1935.4 examples/sec; 0.066 sec/batch)\n",
      "step 9480, loss = 1.00 (1861.8 examples/sec; 0.069 sec/batch)\n",
      "step 9490, loss = 0.78 (1937.3 examples/sec; 0.066 sec/batch)\n",
      "step 9500, loss = 1.02 (1834.9 examples/sec; 0.070 sec/batch)\n",
      "step 9510, loss = 0.84 (1815.2 examples/sec; 0.071 sec/batch)\n",
      "step 9520, loss = 0.81 (1875.6 examples/sec; 0.068 sec/batch)\n",
      "step 9530, loss = 0.84 (1885.0 examples/sec; 0.068 sec/batch)\n",
      "step 9540, loss = 0.84 (1785.2 examples/sec; 0.072 sec/batch)\n",
      "step 9550, loss = 0.64 (1950.1 examples/sec; 0.066 sec/batch)\n",
      "step 9560, loss = 0.77 (1959.9 examples/sec; 0.065 sec/batch)\n",
      "step 9570, loss = 0.72 (1845.8 examples/sec; 0.069 sec/batch)\n",
      "step 9580, loss = 0.71 (1863.3 examples/sec; 0.069 sec/batch)\n",
      "step 9590, loss = 0.79 (1853.1 examples/sec; 0.069 sec/batch)\n",
      "step 9600, loss = 0.86 (1878.1 examples/sec; 0.068 sec/batch)\n",
      "step 9610, loss = 0.54 (1819.1 examples/sec; 0.070 sec/batch)\n",
      "step 9620, loss = 0.71 (1834.7 examples/sec; 0.070 sec/batch)\n",
      "step 9630, loss = 0.90 (1924.0 examples/sec; 0.067 sec/batch)\n",
      "step 9640, loss = 0.81 (1853.8 examples/sec; 0.069 sec/batch)\n",
      "step 9650, loss = 0.74 (1909.6 examples/sec; 0.067 sec/batch)\n",
      "step 9660, loss = 0.68 (1892.6 examples/sec; 0.068 sec/batch)\n",
      "step 9670, loss = 0.78 (1795.3 examples/sec; 0.071 sec/batch)\n",
      "step 9680, loss = 0.85 (1908.4 examples/sec; 0.067 sec/batch)\n",
      "step 9690, loss = 0.66 (1854.2 examples/sec; 0.069 sec/batch)\n",
      "step 9700, loss = 0.77 (1840.5 examples/sec; 0.070 sec/batch)\n",
      "step 9710, loss = 0.91 (1895.9 examples/sec; 0.068 sec/batch)\n",
      "step 9720, loss = 0.67 (1884.6 examples/sec; 0.068 sec/batch)\n",
      "step 9730, loss = 0.64 (1831.4 examples/sec; 0.070 sec/batch)\n",
      "step 9740, loss = 0.72 (1888.4 examples/sec; 0.068 sec/batch)\n",
      "step 9750, loss = 0.78 (1940.0 examples/sec; 0.066 sec/batch)\n",
      "step 9760, loss = 0.82 (1860.2 examples/sec; 0.069 sec/batch)\n",
      "step 9770, loss = 0.76 (1830.3 examples/sec; 0.070 sec/batch)\n",
      "step 9780, loss = 0.75 (1885.3 examples/sec; 0.068 sec/batch)\n",
      "step 9790, loss = 0.82 (1817.9 examples/sec; 0.070 sec/batch)\n",
      "step 9800, loss = 0.82 (1898.7 examples/sec; 0.067 sec/batch)\n",
      "step 9810, loss = 0.85 (1830.6 examples/sec; 0.070 sec/batch)\n",
      "step 9820, loss = 0.81 (1821.3 examples/sec; 0.070 sec/batch)\n",
      "step 9830, loss = 0.76 (1847.4 examples/sec; 0.069 sec/batch)\n",
      "step 9840, loss = 0.77 (1919.8 examples/sec; 0.067 sec/batch)\n",
      "step 9850, loss = 0.62 (1832.5 examples/sec; 0.070 sec/batch)\n",
      "step 9860, loss = 0.86 (1848.9 examples/sec; 0.069 sec/batch)\n",
      "step 9870, loss = 0.87 (1912.1 examples/sec; 0.067 sec/batch)\n",
      "step 9880, loss = 0.85 (1873.5 examples/sec; 0.068 sec/batch)\n",
      "step 9890, loss = 0.79 (1891.3 examples/sec; 0.068 sec/batch)\n",
      "step 9900, loss = 0.62 (1826.0 examples/sec; 0.070 sec/batch)\n",
      "step 9910, loss = 0.69 (1867.2 examples/sec; 0.069 sec/batch)\n",
      "step 9920, loss = 0.91 (1880.6 examples/sec; 0.068 sec/batch)\n",
      "step 9930, loss = 0.70 (1828.4 examples/sec; 0.070 sec/batch)\n",
      "step 9940, loss = 0.81 (1872.8 examples/sec; 0.068 sec/batch)\n",
      "step 9950, loss = 0.65 (1832.9 examples/sec; 0.070 sec/batch)\n",
      "step 9960, loss = 0.80 (1843.1 examples/sec; 0.069 sec/batch)\n",
      "step 9970, loss = 0.64 (1863.4 examples/sec; 0.069 sec/batch)\n",
      "step 9980, loss = 0.94 (1911.9 examples/sec; 0.067 sec/batch)\n",
      "step 9990, loss = 0.73 (1821.4 examples/sec; 0.070 sec/batch)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "max_steps = 10000\n",
    "num_gpus = 2\n",
    "\n",
    "cifar10.maybe_download_and_extract()\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
