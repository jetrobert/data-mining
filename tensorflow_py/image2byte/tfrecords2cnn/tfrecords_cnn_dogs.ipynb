{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "from itertools import groupby\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------training_dataset testing_dataset END --------------------\n",
      "3633\n",
      "3633\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "image_filenames = glob.glob(\"./dataset/StanfordDogs/n02*/*.jpg\")\n",
    "image_filenames[0:2]\n",
    "training_dataset = defaultdict(list)\n",
    "testing_dataset = defaultdict(list)\n",
    "image_filename_with_breed = map(lambda filename: (filename.split(\"/\")[2], \n",
    "                                                 filename), image_filenames)\n",
    "for dog_breed, breed_images in groupby(image_filename_with_breed, lambda x: x[0]):\n",
    "    for i, breed_image in enumerate(breed_images):\n",
    "        if i % 5 == 0:\n",
    "            testing_dataset[dog_breed].append(breed_image[1])\n",
    "        else:\n",
    "            training_dataset[dog_breed].append(breed_image[1])\n",
    "    breed_training_count = len(training_dataset[dog_breed])\n",
    "    breed_testing_count = len(testing_dataset[dog_breed])\n",
    "    breed_training_count_float = float(breed_training_count)\n",
    "    breed_testing_count_float = float(breed_testing_count)\n",
    "    assert round(breed_testing_count_float / (breed_training_count_float + \\\n",
    "        breed_testing_count_float), 2) > 0.18, \"Not enough testing images.\"\n",
    "print(\"------------training_dataset testing_dataset END --------------------\")\n",
    "print(len(testing_dataset))\n",
    "print(len(training_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert images to bytes func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_records_file(dataset, record_location):\n",
    "    writer = None\n",
    "    current_index = 0\n",
    "    for breed, images_filenames in dataset.items():\n",
    "        for image_filename in images_filenames:\n",
    "            if current_index % 100 == 0:\n",
    "                if writer:\n",
    "                    writer.close()\n",
    "                record_filename = \"{record_location}-{current_index}.tfrecords\".format(\n",
    "                    record_location=record_location,\n",
    "                    current_index=current_index)\n",
    "                writer = tf.python_io.TFRecordWriter(record_filename)\n",
    "                print (\"----------------------\"+record_filename + \"---------------------------\") \n",
    "            current_index += 1\n",
    "            image_file = tf.read_file(image_filename)\n",
    "            try:\n",
    "                image = tf.image.decode_jpeg(image_file)\n",
    "            except:\n",
    "                print(image_filename)\n",
    "                continue\n",
    "            grayscale_image = tf.image.rgb_to_grayscale(image)\n",
    "            resized_image = tf.image.resize_images(grayscale_image, [250, 151])\n",
    "            image_bytes = sess.run(tf.cast(resized_image, tf.uint8)).tobytes()\n",
    "            image_label = breed.encode(\"utf-8\")\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "              'label': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_label])),\n",
    "              'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_bytes]))\n",
    "            }))\n",
    "            writer.write(example.SerializeToString())\n",
    "    #writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------write_records_file testing_dataset training_dataset END-------------------\n"
     ]
    }
   ],
   "source": [
    "#write_records_file(testing_dataset, \"./result/test/testing-image\")\n",
    "write_records_file(training_dataset, \"./result/train/training-image\")\n",
    "print(\"------------------write_records_file testing_dataset training_dataset END-------------------\")\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "tf.train.match_filenames_once(\"./result/test/*.tfrecords\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load images from tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------load image from TFRecord END----------------------\n"
     ]
    }
   ],
   "source": [
    "reader = tf.TFRecordReader()\n",
    "_, serialized = reader.read(filename_queue)\n",
    "features = tf.parse_single_example(\n",
    "serialized,\n",
    "    features={\n",
    "        'label': tf.FixedLenFeature([], tf.string),\n",
    "        'image': tf.FixedLenFeature([], tf.string),\n",
    "    })\n",
    "record_image = tf.decode_raw(features['image'], tf.uint8)\n",
    "image = tf.reshape(record_image, [250, 151, 1])\n",
    "label = tf.cast(features['label'], tf.string)\n",
    "min_after_dequeue = 10\n",
    "batch_size = 3\n",
    "capacity = min_after_dequeue + 3 * batch_size\n",
    "image_batch, label_batch = tf.train.shuffle_batch(\n",
    "    [image, label], batch_size=batch_size, capacity=capacity, min_after_dequeue=min_after_dequeue)\n",
    "print(\"---------------------load image from TFRecord END----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# conv and pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------conv2d_layer_one pool_layer_one END--------------------------------\n",
      "-----------------------------conv2d_layer_two pool_layer_two END---------------------------------\n"
     ]
    }
   ],
   "source": [
    "float_image_batch = tf.image.convert_image_dtype(image_batch, tf.float32)\n",
    "conv2d_layer_one = tf.contrib.layers.convolution2d(\n",
    "    float_image_batch,\n",
    "    num_outputs=32,\n",
    "    kernel_size=(5,5),\n",
    "    activation_fn=tf.nn.relu,\n",
    "    weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "    stride=(2, 2),\n",
    "    trainable=True)\n",
    "pool_layer_one = tf.nn.max_pool(conv2d_layer_one,\n",
    "    ksize=[1, 2, 2, 1],\n",
    "    strides=[1, 2, 2, 1],\n",
    "    padding='SAME')\n",
    "conv2d_layer_one.get_shape(), pool_layer_one.get_shape()\n",
    "print(\"--------------------------------conv2d_layer_one pool_layer_one END--------------------------------\")\n",
    "conv2d_layer_two = tf.contrib.layers.convolution2d(\n",
    "    pool_layer_one,\n",
    "    num_outputs=64,\n",
    "    kernel_size=(5,5),\n",
    "    activation_fn=tf.nn.relu,\n",
    "    weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "    stride=(1, 1),\n",
    "    trainable=True)\n",
    "pool_layer_two = tf.nn.max_pool(conv2d_layer_two,\n",
    "    ksize=[1, 2, 2, 1],\n",
    "    strides=[1, 2, 2, 1],\n",
    "    padding='SAME')\n",
    "conv2d_layer_two.get_shape(), pool_layer_two.get_shape()\n",
    "print(\"-----------------------------conv2d_layer_two pool_layer_two END---------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# flattend and fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------flattened_layer_two END-----------------------------------------\n",
      "-----------------------final_fully_connected END--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "flattened_layer_two = tf.reshape(pool_layer_two, [batch_size, -1])\n",
    "flattened_layer_two.get_shape()\n",
    "print(\"----------------------------------------flattened_layer_two END-----------------------------------------\")\n",
    "hidden_layer_three = tf.contrib.layers.fully_connected(\n",
    "    flattened_layer_two, 512,\n",
    "    weights_initializer=lambda i, dtype, partition_info=None: tf.truncated_normal([38912, 512], stddev=0.1),\n",
    "    activation_fn=tf.nn.relu)\n",
    "hidden_layer_three = tf.nn.dropout(hidden_layer_three, 0.1)\n",
    "final_fully_connected = tf.contrib.layers.fully_connected(\n",
    "    hidden_layer_three,\n",
    "    120,\n",
    "    weights_initializer=lambda i, dtype, partition_info=None: tf.truncated_normal([512, 120], stddev=0.1))\n",
    "print(\"-----------------------final_fully_connected END--------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Softmax_2:0\", shape=(3, 120), dtype=float32)\n",
      "--------------------------------train_prediction END---------------------------------------\n",
      "-------------------------------END---------------------------\n"
     ]
    }
   ],
   "source": [
    "labels = list(map(lambda c: c.split(\"/\")[-1], glob.glob(\"./dataset/StanfordDogs/*\")))\n",
    "train_labels = tf.map_fn(lambda l: tf.where(tf.equal(labels, l))[0,0:1][0], label_batch, dtype=tf.int64)\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=final_fully_connected, labels=train_labels))\n",
    "batch = tf.Variable(0)\n",
    "learning_rate = tf.train.exponential_decay(0.01, batch * 3, 120, 0.95, staircase=True)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, 0.9).minimize(loss, global_step=batch)\n",
    "train_prediction = tf.nn.softmax(final_fully_connected)\n",
    "print(train_prediction)\n",
    "print(\"--------------------------------train_prediction END---------------------------------------\")\n",
    "filename_queue.close(cancel_pending_enqueues=True)\n",
    "print(\"-------------------------------END---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
