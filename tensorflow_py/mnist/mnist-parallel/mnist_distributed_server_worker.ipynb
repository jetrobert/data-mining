{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import tempfile\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# parameters on console (flags) and default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "flags.DEFINE_string(\"data_dir\", \"mnist_data\", \"Directory for storing mnist data\")\n",
    "flags.DEFINE_integer(\"hidden_units\", 100, \n",
    "                    \"Number of units in the hidden layer of the NN\")\n",
    "flags.DEFINE_integer(\"train_steps\", 10000,\n",
    "                    \"Number of (global) training steps to perform\")\n",
    "flags.DEFINE_integer(\"batch_size\", 100, \"Training batch size\")\n",
    "flags.DEFINE_integer(\"learning_rate\", 0.01, \"learning rate\")\n",
    "\n",
    "# sync replicas and replicas to aggregate\n",
    "flags.DEFINE_boolean(\"sync_replicas\", False, \n",
    "                    \"Use the sync_replicas (synchronized replicas) mode, \"\n",
    "                    \"wherein the parameter updates from workers are \"\n",
    "                    \"aggregated before applied to avoid stale gradients\")\n",
    "flags.DEFINE_integer(\"replicas_to_aggregate\", None, \n",
    "                    \"Number of replicas to aggregate before parameter \"\n",
    "                    \"update is applied (For sync_replicas mode only; \"\n",
    "                    \"default: num_workers)\")\n",
    "\n",
    "# parameter server and worker host, job and task\n",
    "flags.DEFINE_string(\"ps_hosts\", \"10.167.175.140:2222\", \n",
    "                   \"Comma-separated list of hostname:port pairs\")\n",
    "flags.DEFINE_string(\"worker_hosts\", \"10.167.173.114:2222, 10.167.173.115:2222\",\n",
    "                   \"Comma-separated list of hostname:port pairs\")\n",
    "flags.DEFINE_string(\"job_name\", None, \"job name: worker or ps\")\n",
    "flags.DEFINE_integer(\"task_index\", None,\n",
    "                    \"Worker task index, should be >= 0. task_index=0 is \"\n",
    "                    \"the master worker task the performs the variable initialization\")\n",
    "FLAGS = flags.FLAGS\n",
    "image_pixels = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(unused_argv):\n",
    "    mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)\n",
    "    \n",
    "    # parse ps and worker address\n",
    "    if FLAGS.job_name is None or FLAGS.job_name == \"\":\n",
    "        raise ValueError(\"Must specify an explicit 'job_name'\")\n",
    "    if FLAGS.task_index is None or FLAGS.task_index == \"\":\n",
    "        raise ValueError(\"Must specify an explicit 'task_index'\")\n",
    "    print(\"job name = %s\" % FLAGS.job_name)\n",
    "    print(\"task index = %d\" % FLAGS.task_index)\n",
    "    ps_spec = FLAGS.ps_hosts.split(\",\")\n",
    "    worker_spec = FLAGS.worker_hosts.split(\",\")\n",
    "    \n",
    "    # server to cluster\n",
    "    num_workers = len(worker_spec)\n",
    "    cluster = tf.train.ClusterSpec({\"ps\": ps_spec, \"worker\": worker_spec})\n",
    "    server = tf.train.Server(cluster, job_name=FLAGS.job_name, \n",
    "                            task_index=FLAGS.task_index)\n",
    "    if FLAGS.job_name == \"ps\":\n",
    "        server.join()\n",
    "        \n",
    "    # deploy devices\n",
    "    is_chief = (FLAGS.task_index == 0)\n",
    "    worker_device = \"/job:worker/task:%d/gpu:0\" % FLAGS.task_index\n",
    "    with tf.device(tf.train.replica_device_setter(worker_device=worker_device,\n",
    "                                                 ps_device=\"/job:ps/cpu:0\",\n",
    "                                                 cluster=cluster)):\n",
    "        global_step  = tf.Variable(0, name=\"global_step\", trainable = False)\n",
    "        \n",
    "    # build mlp network\n",
    "    hid_w = tf.Variable(tf.truncated_normal([image_pixels*image_pixels,\n",
    "                FLAGS.hidden_units], stddev=1.0/image_pixels), name=\"hid_w\")\n",
    "    hid_b = tf.Variable(tf.zeros([FLAGS.hidden_units]), name=\"hid_b\")\n",
    "    sm_w = tf.Variable(tf.truncated_normal([FLAGS.hidden_units, 10],\n",
    "                stddev=1.0/math.sqrt(FLAGS.hidden_units)), name=\"sm_w\")\n",
    "    sm_b = tf.Variable(tf.zeros([10]), name=\"sm_b\")\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, [None, image_pixels*image_pixels])\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "    hid_lin = tf.nn.xw_plus_b(x, hid_w, hid_b)\n",
    "    hid = tf.nn.relu(hid_lin)\n",
    "    y = tf.nn.softmax(tf.nn.xw_plus_b(hid, sm_w, sm_b))\n",
    "    cross_entropy = -tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n",
    "    opt = tf.train.AdamOptimizer(FLAGS.learning_rate)\n",
    "    \n",
    "    # sync replicas and optimizer\n",
    "    if FLAGS.sync_replicas:\n",
    "        if FLAGS.replicas_to_aggregate is None:\n",
    "            replicas_to_aggregate = num_workers\n",
    "        else:\n",
    "            replicas_to_aggregate = FLAGS.replicas_to_aggregate\n",
    "        opt = tf.train.SyncReplicasOptimizer(opt, \n",
    "                replicas_to_aggregate=replicas_to_aggregate,\n",
    "                total_num_replicas=num_workers, replica_id=FLAGS.task_index,\n",
    "                name=\"mnist_sync_replicas\")\n",
    "    train_step = opt.minimize(cross_entropy, global_step=global_step)\n",
    "    \n",
    "    # queue runner and global params init\n",
    "    if FLAGS.sync_replicas and is_chief:\n",
    "        chief_queue_runner = opt.get_chief_queue_runner()\n",
    "        init_tokens_op = opt.get_init_tokens_op()\n",
    "        \n",
    "    # local params init and distributed train supervisor\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    train_dir = tempfile.mkdtemp()\n",
    "    sv = tf.train.Supervisor(is_chief=is_chief,\n",
    "                            logdir=train_dir,\n",
    "                            init_op=init_op,\n",
    "                            recovery_wait_secs=1,\n",
    "                            global_step=global_step)\n",
    "    \n",
    "    # session params config\n",
    "    sess_config = tf.ConfigProto(allow_soft_placement=True, \n",
    "                    log_device_placement=False,\n",
    "                    device_filters=[\"/job:ps\", \"/job:worker/task:%d\" % FLAGS.task_index])\n",
    "    if is_chief:\n",
    "        print(\"Worker %d: Initializing session...\" % FLAGS.task_index)\n",
    "    else:\n",
    "        print(\"Worker %d: Waiting for session to be initialized...\" % FLAGS.task_index)\n",
    "    sess = sv.prepare_or_wait_for_session(server.target, config=sess_config)\n",
    "    print(\"Worker %d: Session initialization complete.\" % FLAGS.task_index)\n",
    "    \n",
    "    # sync pattern\n",
    "    if FLAGS.sync_replicas and is_chief:\n",
    "        print(\"Starting chief queue runner and running init_tokens_op\")\n",
    "        sv.start_queue_runners(sess, [chief_queue_runner])\n",
    "        sess.run(init_kokens_op)\n",
    "        \n",
    "    # train\n",
    "    time_begin = time.time()\n",
    "    print(\"Training begins @ %f\" % time_begin)\n",
    "    local_step = 0\n",
    "    while True:\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(FLAGS.batch_size)\n",
    "        train_feed = {x: batch_xs, y_: batch_ys}\n",
    "        \n",
    "        _, step = sess.run([train_step, global_step], feed_dict=train_feed)\n",
    "        local_step += 1\n",
    "        \n",
    "        now = time.time()\n",
    "        print(\"%f: worker %d: training step %d done (global step: %d)\" %\n",
    "             (now, FLAGS.task_index, local_step, step))\n",
    "        \n",
    "        if step >= FLAGS.train_steps:\n",
    "            break\n",
    "            \n",
    "    # training time and loss results\n",
    "    time_end = time.time()\n",
    "    print(\"Training ends @ %f\" % time_end)\n",
    "    training_time = time_end - time_begin\n",
    "    print(\"Training elapsed time: %f s\" % training_time)\n",
    "    \n",
    "    val_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n",
    "    val_xent = sess.run(cross_entropy, feed_dict=val_feed)\n",
    "    print(\"After %d training step(s), validation cross entropy = %g\" %\n",
    "         (FLAGS.train_steps, val_xent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting mnist_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting mnist_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting mnist_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must specify an explicit 'job_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ce29dcffb130>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mflags_passthrough\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-b496f9da2d5b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(unused_argv)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# parse ps and worker address\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must specify an explicit 'job_name'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must specify an explicit 'task_index'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Must specify an explicit 'job_name'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# starting on different devices with follow commands:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python codename.py --job_name=ps --task_index=0\n",
    "### python codename.py --job_name=worker --task_index=0\n",
    "### python codename.py --job_name=worker --task_index=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# starting on different devices with sync_replicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python codename.py --job_name=ps --task_index=0 --sync_replicas=True\n",
    "### python codename.py --job_name=worker --task_index=0 --sync_replicas=True\n",
    "### python codename.py --job_name=worker --task_index=1 --sync_replicas=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
